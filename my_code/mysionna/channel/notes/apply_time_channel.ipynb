{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow version\n",
    "这段代码定义了一个名为 `ApplyTimeChannel` 的 TensorFlow 层，它用于将时域信道响应应用于信道输入。这种操作通常用于通信系统的模拟和测试。以下是对代码的详细分析：\n",
    "\n",
    "### 类定义和文档字符串\n",
    "#### 类头和文档字符串\n",
    "```python\n",
    "class ApplyTimeChannel(tf.keras.layers.Layer):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"ApplyTimeChannel(num_time_samples, l_tot, add_awgn=True, dtype=tf.complex64, **kwargs)\n",
    "    ...\n",
    "    \"\"\"\n",
    "```\n",
    "- `ApplyTimeChannel` 继承自 `tf.keras.layers.Layer`。\n",
    "- 文档字符串详细说明了类的用途、参数、输入和输出。\n",
    "\n",
    "### 初始化方法 `__init__`\n",
    "```python\n",
    "def __init__(self, num_time_samples, l_tot, add_awgn=True,\n",
    "             dtype=tf.complex64, **kwargs):\n",
    "\n",
    "    super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "\n",
    "    self._add_awgn = add_awgn\n",
    "```\n",
    "- 初始化方法接收几个参数：`num_time_samples`（信道输入的时间样本数）、`l_tot`（信道滤波器的长度）、`add_awgn`（是否添加白噪声）和 `dtype`（数据类型）。\n",
    "- 调用 `super().__init__` 初始化基类，并设置层不可训练。\n",
    "\n",
    "### 创建 Toeplitz 矩阵\n",
    "```python\n",
    "    first_colum = np.concatenate([  np.arange(0, num_time_samples),\n",
    "                                    np.full([l_tot-1], num_time_samples)])\n",
    "    first_row = np.concatenate([[0], np.full([l_tot-1], num_time_samples)])\n",
    "    self._g = scipy.linalg.toeplitz(first_colum, first_row)\n",
    "```\n",
    "- 生成一个 Toeplitz 矩阵 `_g`，用于将输入信号与信道响应进行卷积操作。矩阵的行和列通过 `first_colum` 和 `first_row` 定义。\n",
    "\n",
    "### `build` 方法\n",
    "```python\n",
    "def build(self, input_shape): #pylint: disable=unused-argument\n",
    "\n",
    "    if self._add_awgn:\n",
    "        self._awgn = AWGN(dtype=self.dtype)\n",
    "```\n",
    "- `build` 方法在第一次使用层时调用。如果需要添加 AWGN（加性白噪声），则初始化一个 `AWGN` 层。\n",
    "\n",
    "### `call` 方法\n",
    "```python\n",
    "def call(self, inputs):\n",
    "\n",
    "    if self._add_awgn:\n",
    "        x, h_time, no = inputs\n",
    "    else:\n",
    "        x, h_time = inputs\n",
    "```\n",
    "- `call` 方法是实际应用层逻辑的地方。根据是否添加 AWGN，从 `inputs` 元组中解包输入信号 `x`、信道响应 `h_time` 和噪声功率 `no`（如果适用）。\n",
    "\n",
    "#### 准备信道输入\n",
    "```python\n",
    "    x = tf.pad(x, [[0,0], [0,0], [0,0], [0,1]])\n",
    "    x = insert_dims(x, 2, axis=1)\n",
    "\n",
    "    x = tf.gather(x, self._g, axis=-1)\n",
    "```\n",
    "- 将输入信号 `x` 填充一个零以便进行矩阵操作。\n",
    "- 使用 `insert_dims` 函数调整输入信号的维度。\n",
    "- 使用 `_g` 矩阵将输入信号 `x` 收集到合适的位置，以便与信道响应进行卷积。\n",
    "\n",
    "#### 应用信道响应\n",
    "```python\n",
    "    y = tf.reduce_sum(h_time*x, axis=-1)\n",
    "    y = tf.reduce_sum(tf.reduce_sum(y, axis=4), axis=3)\n",
    "```\n",
    "- 对输入信号 `x` 和信道响应 `h_time` 进行逐元素相乘，然后沿指定轴求和以得到输出信号 `y`。\n",
    "\n",
    "#### 添加 AWGN\n",
    "```python\n",
    "    if self._add_awgn:\n",
    "        y = self._awgn((y, no))\n",
    "```\n",
    "- 如果需要，调用 `AWGN` 层将加性白噪声添加到输出信号 `y` 中。\n",
    "\n",
    "#### 返回输出\n",
    "```python\n",
    "    return y\n",
    "```\n",
    "- 返回最终的信道输出 `y`。\n",
    "\n",
    "### 总结\n",
    "`ApplyTimeChannel` 层用于模拟通信系统中信号在时域上的传输过程。它通过卷积操作将输入信号与信道响应进行卷积，并可选择性地添加加性白噪声。此实现利用了 TensorFlow 的高级接口，使其能够作为 Keras 模型的一部分进行训练和评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将这个 TensorFlow 代码转换成 PyTorch 版本需要做以下几步：\n",
    "\n",
    "1. **将 TensorFlow 的层转化为 PyTorch 的层**。\n",
    "2. **将 TensorFlow 操作（如 `pad`, `gather`, `reduce_sum` 等）转化为 PyTorch 的等价操作**。\n",
    "3. **调整数据维度以适应 PyTorch 的数据格式**。\n",
    "4. **实现 AWGN 层**。\n",
    "\n",
    "以下是转换后的代码：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "class AWGN(nn.Module):\n",
    "    def __init__(self, dtype=torch.complex64):\n",
    "        super(AWGN, self).__init__()\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, no = inputs\n",
    "        noise = torch.sqrt(0.5 * no) * (torch.randn_like(x) + 1j * torch.randn_like(x))\n",
    "        return x + noise\n",
    "\n",
    "class ApplyTimeChannel(nn.Module):\n",
    "    def __init__(self, num_time_samples, l_tot, add_awgn=True, dtype=torch.complex64):\n",
    "        super(ApplyTimeChannel, self).__init__()\n",
    "        self.add_awgn = add_awgn\n",
    "        self.dtype = dtype\n",
    "\n",
    "        first_column = np.concatenate([np.arange(0, num_time_samples), np.full([l_tot - 1], num_time_samples)])\n",
    "        first_row = np.concatenate([[0], np.full([l_tot - 1], num_time_samples)])\n",
    "        self.g = torch.tensor(scipy.linalg.toeplitz(first_column, first_row), dtype=torch.long)\n",
    "\n",
    "        if self.add_awgn:\n",
    "            self.awgn = AWGN(dtype=dtype)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.add_awgn:\n",
    "            x, h_time, no = inputs\n",
    "        else:\n",
    "            x, h_time = inputs\n",
    "\n",
    "        # Prepare the channel input for broadcasting and matrix multiplication\n",
    "        x = F.pad(x, (0, 1))\n",
    "        x = x.unsqueeze(2)\n",
    "\n",
    "        # Gather operation similar to TensorFlow's gather\n",
    "        x = torch.gather(x, -1, self.g.unsqueeze(0).unsqueeze(0).unsqueeze(0).expand(x.size(0), x.size(1), x.size(2), -1, -1))\n",
    "\n",
    "        # Apply the channel response\n",
    "        y = torch.sum(h_time * x, dim=-1)\n",
    "        y = torch.sum(torch.sum(y, dim=4), dim=3)\n",
    "\n",
    "        # Add AWGN if requested\n",
    "        if self.add_awgn:\n",
    "            y = self.awgn((y, no))\n",
    "\n",
    "        return y\n",
    "\n",
    "# Example usage\n",
    "num_time_samples = 10\n",
    "l_tot = 4\n",
    "batch_size = 2\n",
    "num_tx = 3\n",
    "num_tx_ant = 2\n",
    "num_rx = 2\n",
    "num_rx_ant = 2\n",
    "\n",
    "x = torch.randn(batch_size, num_tx, num_tx_ant, num_time_samples, dtype=torch.complex64)\n",
    "h_time = torch.randn(batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_tot - 1, l_tot, dtype=torch.complex64)\n",
    "no = torch.randn(batch_size, num_rx, num_rx_ant, num_time_samples + l_tot - 1, dtype=torch.float32)\n",
    "\n",
    "layer = ApplyTimeChannel(num_time_samples, l_tot, add_awgn=True, dtype=torch.complex64)\n",
    "output = layer((x, h_time, no))\n",
    "print(output.shape)  # should be [batch_size, num_rx, num_rx_ant, num_time_samples + l_tot - 1]\n",
    "```\n",
    "\n",
    "### 详细解释\n",
    "1. **AWGN 层**:\n",
    "   - 用 PyTorch 实现 AWGN 噪声添加层。\n",
    "\n",
    "2. **ApplyTimeChannel 类**:\n",
    "   - 初始化时，创建 Toeplitz 矩阵 `g` 用于 gather 操作。\n",
    "   - `forward` 方法：\n",
    "     - 通过 `F.pad` 函数在信道输入的最后一个维度上填充一个零。\n",
    "     - 使用 `unsqueeze` 增加一个维度以便进行矩阵乘法。\n",
    "     - 使用 `torch.gather` 函数来模拟 TensorFlow 的 gather 操作。\n",
    "     - 进行信道响应应用和加法运算。\n",
    "     - 在需要时调用 AWGN 层添加噪声。\n",
    "\n",
    "3. **Example usage**:\n",
    "   - 该示例展示了如何创建 `ApplyTimeChannel` 层并传入适当的输入数据。\n",
    "\n",
    "这段代码应该与 TensorFlow 版本的功能等效，可以用 PyTorch 实现同样的信道响应应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "\n",
    "class AWGN(nn.Module):\n",
    "    def __init__(self, dtype=torch.complex64):\n",
    "        super(AWGN, self).__init__()\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, no = inputs\n",
    "        noise = torch.sqrt(0.5 * no) * (torch.randn_like(x) + 1j * torch.randn_like(x))\n",
    "        return x + noise\n",
    "\n",
    "class ApplyTimeChannel(nn.Module):\n",
    "    def __init__(self, num_time_samples, l_tot, add_awgn=True, dtype=torch.complex64):\n",
    "        super(ApplyTimeChannel, self).__init__()\n",
    "        self.add_awgn = add_awgn\n",
    "        self.dtype = dtype\n",
    "\n",
    "        first_column = np.concatenate([np.arange(0, num_time_samples), np.full([l_tot - 1], num_time_samples)])\n",
    "        first_row = np.concatenate([[0], np.full([l_tot - 1], num_time_samples)])\n",
    "        self.g = torch.tensor(scipy.linalg.toeplitz(first_column, first_row), dtype=torch.long)\n",
    "\n",
    "        if self.add_awgn:\n",
    "            self.awgn = AWGN(dtype=dtype)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.add_awgn:\n",
    "            x, h_time, no = inputs\n",
    "        else:\n",
    "            x, h_time = inputs\n",
    "\n",
    "        # Prepare the channel input for broadcasting and matrix multiplication\n",
    "        x = F.pad(x, (0, 1))\n",
    "        x = x.unsqueeze(2)\n",
    "\n",
    "        # Gather operation similar to TensorFlow's gather\n",
    "        x = torch.gather(x, -1, self.g.unsqueeze(0).unsqueeze(0).unsqueeze(0).expand(x.size(0), x.size(1), x.size(2), -1, -1))\n",
    "\n",
    "        # Apply the channel response\n",
    "        y = torch.sum(h_time * x, dim=-1)\n",
    "        y = torch.sum(torch.sum(y, dim=4), dim=3)\n",
    "\n",
    "        # Add AWGN if requested\n",
    "        if self.add_awgn:\n",
    "            y = self.awgn((y, no))\n",
    "\n",
    "        return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "num_time_samples = 10\n",
    "l_tot = 4\n",
    "batch_size = 2\n",
    "num_tx = 3\n",
    "num_tx_ant = 2\n",
    "num_rx = 2\n",
    "num_rx_ant = 2\n",
    "\n",
    "x = torch.randn(batch_size, num_tx, num_tx_ant, num_time_samples, dtype=torch.complex64)\n",
    "h_time = torch.randn(batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_tot - 1, l_tot, dtype=torch.complex64)\n",
    "no = torch.randn(batch_size, num_rx, num_rx_ant, num_time_samples + l_tot - 1, dtype=torch.float32)\n",
    "\n",
    "layer = ApplyTimeChannel(num_time_samples, l_tot, add_awgn=True, dtype=torch.complex64)\n",
    "output = layer((x, h_time, no))\n",
    "print(output.shape)  # should be [batch_size, num_rx, num_rx_ant, num_time_samples + l_tot - 1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
