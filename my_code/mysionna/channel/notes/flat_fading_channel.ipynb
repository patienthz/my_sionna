{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenerateFlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sionna.channel import AWGN\n",
    "from sionna.utils import complex_normal\n",
    "\n",
    "class GenerateFlatFadingChannel():\n",
    "    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._dtype = dtype\n",
    "        self.spatial_corr = spatial_corr\n",
    "\n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._spatial_corr\n",
    "\n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._spatial_corr = value\n",
    "\n",
    "    def __call__(self, batch_size):\n",
    "        # Generate standard complex Gaussian matrices\n",
    "        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n",
    "        h = complex_normal(shape, dtype=self._dtype)\n",
    "\n",
    "        # Apply spatial correlation\n",
    "        if self.spatial_corr is not None:\n",
    "            h = self.spatial_corr(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated channel matrices with spatial correlation:\n",
      "tf.Tensor(\n",
      "[[[ 0.28819647-0.18808052j  0.75670254-0.49159977j\n",
      "    0.5917811 -0.12480513j  0.63494235-0.37096283j]\n",
      "  [ 0.8017786 -0.11795726j -0.02173579-0.07250741j\n",
      "   -0.61142975+0.3283163j  -1.3197908 +0.37896475j]]\n",
      "\n",
      " [[-0.81450444-0.5996711j  -0.7622298 -0.3086362j\n",
      "   -0.67319655-1.4973358j  -0.3295982 -1.1230161j ]\n",
      "  [-0.83335257-0.68523586j -0.72149324-1.1087103j\n",
      "   -1.085548  -1.2565811j  -1.0349623 -1.3363783j ]]], shape=(2, 2, 4), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "from sionna.channel.spatial_correlation import SpatialCorrelation\n",
    "class SimpleSpatialCorrelation(SpatialCorrelation):\n",
    "    def __init__(self, correlation_matrix):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        correlation_matrix : tf.Tensor\n",
    "            A square matrix used to introduce spatial correlation.\n",
    "        \"\"\"\n",
    "        self.correlation_matrix = tf.cast(correlation_matrix, tf.complex64)\n",
    "\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        # Apply the correlation matrix to the input tensor\n",
    "        h_shape = tf.shape(h)\n",
    "        h_reshaped = tf.reshape(h, [-1, h_shape[-1]])\n",
    "        h_corr_reshaped = tf.matmul(h_reshaped, self.correlation_matrix)\n",
    "        h_corr = tf.reshape(h_corr_reshaped, h_shape)\n",
    "        return h_corr \n",
    "def test_generate_flat_fading_channel_with_spatial_corr():\n",
    "    # Parameters\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    # Define a simple correlation matrix\n",
    "    correlation_matrix = tf.constant([[1.0, 0.5, 0.5, 0.2],\n",
    "                                      [0.5, 1.0, 0.3, 0.4],\n",
    "                                      [0.5, 0.3, 1.0, 0.6],\n",
    "                                      [0.2, 0.4, 0.6, 1.0]], dtype=tf.float32)\n",
    "    \n",
    "    # Initialize the SimpleSpatialCorrelation instance\n",
    "    spatial_corr = SimpleSpatialCorrelation(correlation_matrix)\n",
    "    \n",
    "    # Initialize the GenerateFlatFadingChannel instance\n",
    "    channel_generator = GenerateFlatFadingChannel(\n",
    "        num_tx_ant=num_tx_ant,\n",
    "        num_rx_ant=num_rx_ant,\n",
    "        spatial_corr=spatial_corr,  # Use the SimpleSpatialCorrelation instance\n",
    "        dtype=tf.complex64\n",
    "    )\n",
    "\n",
    "    # Generate a batch of channel matrices\n",
    "    h = channel_generator(batch_size)\n",
    "\n",
    "    # Print the output\n",
    "    print(\"Generated channel matrices with spatial correlation:\")\n",
    "    print(h)\n",
    "test_generate_flat_fading_channel_with_spatial_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ApplyFlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传输向量:\n",
      "[[ 1.1132426 +0.11130638j -0.5319816 +0.5356469j   1.396718  -1.6788299j\n",
      "  -2.1668339 +0.6576924j ]\n",
      " [ 0.21215717-1.3061938j   0.10999919-0.31190628j -0.7991015 -0.01790807j\n",
      "   0.07831591+1.3733525j ]\n",
      " [ 0.4104208 -2.1528537j  -0.66589326-1.8302702j   1.5569323 -1.5798086j\n",
      "  -0.18739842+1.2966088j ]]\n",
      "\n",
      "信道矩阵:\n",
      "[[[ 0.16454397+0.6013255j  -1.2538235 +1.7570105j\n",
      "   -0.5845626 -0.6918303j  -1.4415432 +0.11925775j]\n",
      "  [-0.33987543+0.4709389j  -2.607881  -0.3853946j\n",
      "   -0.7426765 -1.6712811j  -0.7299179 -0.16972645j]]\n",
      "\n",
      " [[-0.2922164 -0.13243763j  1.1041995 -0.87678397j\n",
      "    2.12758   +0.82741284j  0.00658638+0.45426363j]\n",
      "  [-0.5833805 -1.1152693j  -1.8485973 -0.74552035j\n",
      "   -0.03089342-0.23460677j  0.694645  -0.21249084j]]\n",
      "\n",
      " [[ 2.0911696 +0.4285976j  -0.54920936-0.19643413j\n",
      "    0.6413635 +0.38148257j  1.2151476 -0.05950265j]\n",
      "  [ 0.41378117+0.46881416j  0.49113128+0.577954j\n",
      "   -0.27631778+1.3978186j   0.4066226 +0.5923779j ]]]\n",
      "\n",
      "加了AWGN后的输出向量:\n",
      "[[ 1.5141959-1.8787501j  -0.9935119-1.8785846j ]\n",
      " [-2.296244 -0.71299666j -1.5069779+1.6709458j ]\n",
      " [ 3.001557 -1.9874233j   2.9112024+1.6642246j ]]\n"
     ]
    }
   ],
   "source": [
    "class ApplyFlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self, add_awgn=True, dtype=tf.complex64, **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._add_awgn = add_awgn\n",
    "\n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "        if self._add_awgn:\n",
    "            self._awgn = AWGN(dtype=self.dtype)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, h, no = inputs\n",
    "        else:\n",
    "            x, h = inputs\n",
    "\n",
    "        x = tf.expand_dims(x, axis=-1)\n",
    "        y = tf.matmul(h, x)\n",
    "        y = tf.squeeze(y, axis=-1)\n",
    "\n",
    "        if self._add_awgn:\n",
    "            y = self._awgn((y, no))\n",
    "\n",
    "        return y\n",
    "def test_apply_flat_fading_channel():\n",
    "    # 定义参数\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 3\n",
    "\n",
    "    # 生成输入数据\n",
    "    x = tf.complex(tf.random.normal([batch_size, num_tx_ant]),\n",
    "                tf.random.normal([batch_size, num_tx_ant]))\n",
    "\n",
    "    # 生成信道矩阵\n",
    "    h = tf.complex(tf.random.normal([batch_size, num_rx_ant, num_tx_ant]),\n",
    "                tf.random.normal([batch_size, num_rx_ant, num_tx_ant]))\n",
    "\n",
    "    # 定义噪声功率\n",
    "    no = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "    # 初始化 ApplyFlatFadingChannel 类\n",
    "    apply_channel = ApplyFlatFadingChannel(add_awgn=True, dtype=tf.complex64)\n",
    "\n",
    "    # 构建计算图\n",
    "    y = apply_channel((x, h, no))\n",
    "\n",
    "    # 打印输出结果\n",
    "    print(\"传输向量:\")\n",
    "    print(x.numpy())\n",
    "    print(\"\\n信道矩阵:\")\n",
    "    print(h.numpy())\n",
    "    print(\"\\n加了AWGN后的输出向量:\")\n",
    "    print(y.numpy())\n",
    "test_apply_flat_fading_channel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sionna.channel import GenerateFlatFadingChannel, ApplyFlatFadingChannel\n",
    "class FlatFadingChannel(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_tx_ant,\n",
    "                 num_rx_ant,\n",
    "                 spatial_corr=None,\n",
    "                 add_awgn=True,\n",
    "                 return_channel=False,\n",
    "                 dtype=tf.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "        self._gen_chn = GenerateFlatFadingChannel(self._num_tx_ant,\n",
    "                                                  self._num_rx_ant,\n",
    "                                                  spatial_corr,\n",
    "                                                  dtype=dtype)\n",
    "        self._app_chn = ApplyFlatFadingChannel(add_awgn=add_awgn, dtype=dtype)\n",
    "\n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._gen_chn.spatial_corr\n",
    "\n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._gen_chn.spatial_corr = value\n",
    "\n",
    "    @property\n",
    "    def generate(self):\n",
    "        \"\"\"Calls the internal :class:`GenerateFlatFadingChannel`.\"\"\"\n",
    "        return self._gen_chn\n",
    "\n",
    "    @property\n",
    "    def apply(self):\n",
    "        \"\"\"Calls the internal :class:`ApplyFlatFadingChannel`.\"\"\"\n",
    "        return self._app_chn\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "\n",
    "        # Generate a batch of channel realizations\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        h = self._gen_chn(batch_size)\n",
    "\n",
    "        # Apply the channel to the input\n",
    "        if self._add_awgn:\n",
    "            y = self._app_chn([x, h, no])\n",
    "        else:\n",
    "            y = self._app_chn([x, h])\n",
    "\n",
    "        if self._return_channel:\n",
    "            return y, h\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传输向量:\n",
      "tf.Tensor(\n",
      "[[ 0.6843453 +0.22757216j -0.26122835+1.0375805j   0.2260131 +2.4184716j\n",
      "  -1.0160859 +0.50326806j]\n",
      " [ 0.48190844+0.27828395j  0.92021644+0.57757956j -0.22269917+0.5953742j\n",
      "  -0.18767054+0.5871959j ]\n",
      " [ 0.7211384 -0.13487098j  0.1657252 -0.8465592j  -1.0538555 -0.17256583j\n",
      "  -0.7745284 +0.21054038j]], shape=(3, 4), dtype=complex64)\n",
      "\n",
      "信道矩阵:\n",
      "tf.Tensor(\n",
      "[[[-0.5358709 +0.611553j   -0.40919942-1.7566687j\n",
      "   -0.7247089 -0.41668743j  0.42145267-0.30306837j]\n",
      "  [ 0.5341157 +2.09381j    -0.47984308+0.23437928j\n",
      "   -0.62534195+0.66592836j  0.87496334+0.34314734j]]\n",
      "\n",
      " [[ 0.24807462-0.3962823j  -0.50909466-0.12608887j\n",
      "    0.42017648-0.5143275j  -0.0468226 +0.0418671j ]\n",
      "  [-0.56326246-0.55790615j -0.21070991+0.13739674j\n",
      "    0.37893227+0.35578674j -0.11870175-0.10376992j]]\n",
      "\n",
      " [[-0.21596894-0.06639432j -0.6416581 -0.4427852j\n",
      "   -0.17835604+0.8335447j  -0.3046067 +1.4488416j ]\n",
      "  [ 0.5513172 -0.8785j      0.33442724-0.8733942j\n",
      "   -1.1926903 +0.00908366j  0.1839229 -0.1777566j ]]], shape=(3, 2, 4), dtype=complex64)\n",
      "\n",
      "加了AWGN后的输出向量:\n",
      "tf.Tensor(\n",
      "[[ 1.8878946 -1.0866878j  -3.1755269 -0.34868747j]\n",
      " [ 0.14315084+0.0387474j  -0.6763506 -0.56337464j]\n",
      " [-0.40993562-1.34766j     0.3728577 -1.0078685j ]], shape=(3, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "def test_flat_fading_channel():\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 3\n",
    "\n",
    "    x_real = tf.random.normal([batch_size, num_tx_ant], dtype=tf.float32)\n",
    "    x_imag = tf.random.normal([batch_size, num_tx_ant], dtype=tf.float32)\n",
    "    x = tf.complex(x_real, x_imag)\n",
    "    \n",
    "    no = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "    flat_fading_channel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\n",
    "\n",
    "    y, h = flat_fading_channel((x, no))\n",
    "\n",
    "    print(\"传输向量:\")\n",
    "    print(x)\n",
    "    print(\"\\n信道矩阵:\")\n",
    "    print(h)\n",
    "    print(\"\\n加了AWGN后的输出向量:\")\n",
    "    print(y)\n",
    "test_flat_fading_channel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenerateFlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from my_code.mysionna.channel.torch_version import AWGN\n",
    "\n",
    "from my_code.mysionna.utils import complex_normal\n",
    "\n",
    "class SimpleSpatialCorrelation(SpatialCorrelation):\n",
    "    def __init__(self, correlation_matrix):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        correlation_matrix : torch.Tensor\n",
    "            A square matrix used to introduce spatial correlation.\n",
    "        \"\"\"\n",
    "        self.correlation_matrix = correlation_matrix.type(torch.complex64)\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        # Apply the correlation matrix to the input tensor\n",
    "        h_shape = h.shape\n",
    "        h_reshaped = h.view(-1, h_shape[-1])\n",
    "        h_corr_reshaped = torch.matmul(h_reshaped, self.correlation_matrix)\n",
    "        h_corr = h_corr_reshaped.view(h_shape)\n",
    "        return h_corr\n",
    "class GenerateFlatFadingChannel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=torch.complex64, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._dtype = dtype\n",
    "        self.spatial_corr = spatial_corr\n",
    "\n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._spatial_corr\n",
    "\n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._spatial_corr = value\n",
    "\n",
    "    def __call__(self, batch_size):\n",
    "        # Generate standard complex Gaussian matrices\n",
    "        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n",
    "        h = complex_normal(shape, dtype=self._dtype)\n",
    "\n",
    "        # Apply spatial correlation\n",
    "        if self.spatial_corr is not None:\n",
    "            h = self.spatial_corr(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated channel matrices with spatial correlation:\n",
      "tensor([[[-0.7127+0.8141j, -0.8704+0.5202j, -0.3839+0.0325j, -0.2602+0.1362j],\n",
      "         [-0.7857+0.5532j, -0.2742+1.0451j,  0.4278+1.1164j,  0.1717+1.3110j]],\n",
      "\n",
      "        [[-0.6055+0.6815j, -0.8914+1.1921j, -0.7499+1.1598j, -1.3174+1.5669j],\n",
      "         [-1.7984+0.6477j, -1.4103+0.8763j, -0.2251+0.1602j,  0.1251+0.2173j]]])\n"
     ]
    }
   ],
   "source": [
    "def test_generate_flat_fading_channel_with_spatial_corr():\n",
    "    # Parameters\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 2\n",
    "\n",
    "    # Define a simple correlation matrix\n",
    "    correlation_matrix = torch.tensor([[1.0, 0.5, 0.5, 0.2],\n",
    "                                       [0.5, 1.0, 0.3, 0.4],\n",
    "                                       [0.5, 0.3, 1.0, 0.6],\n",
    "                                       [0.2, 0.4, 0.6, 1.0]], dtype=torch.float32)\n",
    "    \n",
    "    # Initialize the SimpleSpatialCorrelation instance\n",
    "    spatial_corr = SimpleSpatialCorrelation(correlation_matrix)\n",
    "    \n",
    "    # Initialize the GenerateFlatFadingChannel instance\n",
    "    channel_generator = GenerateFlatFadingChannel(\n",
    "        num_tx_ant=num_tx_ant,\n",
    "        num_rx_ant=num_rx_ant,\n",
    "        spatial_corr=spatial_corr,  # Use the SimpleSpatialCorrelation instance\n",
    "        dtype=torch.complex64\n",
    "    )\n",
    "\n",
    "    # Generate a batch of channel matrices\n",
    "    h = channel_generator(batch_size)\n",
    "\n",
    "    # Print the output\n",
    "    print(\"Generated channel matrices with spatial correlation:\")\n",
    "    print(h)\n",
    "test_generate_flat_fading_channel_with_spatial_corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ApplyFlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyFlatFadingChannel(nn.Module):\n",
    "    def __init__(self, add_awgn=True, dtype=torch.complex64, **kwargs):\n",
    "        # super().__init__(requires_grad=False, dtype=dtype, **kwargs)\n",
    "        super().__init__()\n",
    "        self._add_awgn = add_awgn\n",
    "        if self._add_awgn:\n",
    "            self._awgn = AWGN(dtype=dtype)\n",
    "    \n",
    "\n",
    "    def forward(self,inputs):\n",
    "        if self._add_awgn:\n",
    "            x, h, no = inputs\n",
    "        else:\n",
    "            x, h = inputs\n",
    "        \n",
    "        x = x.unsqueeze(-1)\n",
    "        y = torch.matmul(h, x)\n",
    "        y = y.squeeze(-1)\n",
    "\n",
    "        if self._add_awgn:\n",
    "            y = self._awgn((y,no))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传输向量:\n",
      "tensor([[ 0.1313-0.6977j,  0.0559+0.5227j,  1.2121-0.5464j,  0.6020+1.2260j],\n",
      "        [ 0.2297+0.2950j,  0.2082+1.0829j,  1.4587-0.3842j, -0.1091-0.9006j],\n",
      "        [ 0.4567+0.4774j,  0.4373-0.4676j,  0.2499-0.5733j,  0.4973-0.1342j]])\n",
      "\n",
      "信道矩阵:\n",
      "tensor([[[ 0.3331-0.1603j, -0.3885+0.6694j,  0.7061+0.1668j, -0.1577+0.0903j],\n",
      "         [-0.9079+0.8356j,  0.8097+1.2289j,  0.2214+0.9629j, -2.3175-0.9456j]],\n",
      "\n",
      "        [[-0.3671-0.0244j,  0.1677+1.0710j,  0.2633+0.4018j,  0.1188+1.1061j],\n",
      "         [-0.1680-0.8280j, -0.3419+0.1864j, -1.2192-1.0328j, -0.7579+0.3268j]],\n",
      "\n",
      "        [[-0.1402+0.2742j, -0.9989+0.2292j, -1.0726+1.3798j,  0.1012+0.7148j],\n",
      "         [ 0.1439-0.3031j,  0.7712-0.6016j,  0.5720+0.2786j, -0.9295-0.3365j]]])\n",
      "\n",
      "加了AWGN后的输出向量:\n",
      "tensor([[ 0.3631-0.7183j,  0.3706-1.1167j],\n",
      "        [ 0.4548+0.2452j, -1.6224-1.1649j],\n",
      "        [ 0.2085+1.8357j, -0.2450-0.8538j]])\n"
     ]
    }
   ],
   "source": [
    "def test_apply_flat_fading_channel():\n",
    "    # 定义参数\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 3\n",
    "\n",
    "    # 生成输入数据\n",
    "    x = torch.randn(batch_size, num_tx_ant, dtype=torch.cfloat)\n",
    "\n",
    "    # 生成信道矩阵\n",
    "    h = torch.randn(batch_size, num_rx_ant, num_tx_ant, dtype=torch.cfloat)\n",
    "\n",
    "    # 定义噪声功率\n",
    "    no = torch.tensor(0.1, dtype=torch.float32)\n",
    "\n",
    "    # 初始化 ApplyFlatFadingChannel 类\n",
    "    apply_channel = ApplyFlatFadingChannel(add_awgn=True)\n",
    "\n",
    "    # 构建计算图\n",
    "    y = apply_channel((x, h, no))\n",
    "\n",
    "    # 打印输出结果\n",
    "    print(\"传输向量:\")\n",
    "    print(x)\n",
    "    print(\"\\n信道矩阵:\")\n",
    "    print(h)\n",
    "    print(\"\\n加了AWGN后的输出向量:\")\n",
    "    print(y)\n",
    "test_apply_flat_fading_channel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlatFadingChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatFadingChannel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_tx_ant,\n",
    "                 num_rx_ant,\n",
    "                 spatial_corr=None,\n",
    "                 add_awgn=True,\n",
    "                 return_channel=False,\n",
    "                 dtype=torch.complex64,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self._num_tx_ant = num_tx_ant\n",
    "        self._num_rx_ant = num_rx_ant\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "        self._gen_chn = GenerateFlatFadingChannel(self._num_tx_ant,\n",
    "                                                  self._num_rx_ant,\n",
    "                                                  spatial_corr,\n",
    "                                                  dtype=dtype)\n",
    "        self._app_chn = ApplyFlatFadingChannel(add_awgn=add_awgn, dtype=dtype)\n",
    "\n",
    "    @property\n",
    "    def spatial_corr(self):\n",
    "        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n",
    "        return self._gen_chn.spatial_corr\n",
    "\n",
    "    @spatial_corr.setter\n",
    "    def spatial_corr(self, value):\n",
    "        self._gen_chn.spatial_corr = value\n",
    "\n",
    "    @property\n",
    "    def generate(self):\n",
    "        \"\"\"Calls the internal :class:`GenerateFlatFadingChannel`.\"\"\"\n",
    "        return self._gen_chn\n",
    "\n",
    "    @property\n",
    "    def apply(self):\n",
    "        \"\"\"Calls the internal :class:`ApplyFlatFadingChannel`.\"\"\"\n",
    "        return self._app_chn\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self._add_awgn:\n",
    "            x, no =inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "        \n",
    "        # Generate a batch of channel realizations\n",
    "        batch_size = x.shape[0]\n",
    "        h = self._gen_chn(batch_size)\n",
    "\n",
    "        # Apply the channel to the input\n",
    "        if self._add_awgn:\n",
    "            y = self._app_chn([x, h, no])\n",
    "        else:\n",
    "            y = self._app_chn([x, h])\n",
    "\n",
    "        if self._return_channel:\n",
    "            return y, h\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "传输向量:\n",
      "tensor([[ 0.2329-1.1059j, -0.8660+0.3665j, -0.1342-1.3872j,  0.0426+0.5944j],\n",
      "        [ 0.8383-0.0249j,  0.2961+1.1384j,  0.3307+0.4614j,  1.1108-0.0269j],\n",
      "        [ 1.2513+0.3599j, -0.4263+0.2140j,  0.3840+0.2187j, -0.6161+0.5226j]])\n",
      "\n",
      "信道矩阵:\n",
      "tensor([[[-0.8303-0.1415j, -1.1471-0.2949j, -0.5462+1.3484j, -0.1300+1.3192j],\n",
      "         [-1.0897+0.2057j,  2.1578-0.3344j,  0.6888+0.0411j,  0.2210-1.2011j]],\n",
      "\n",
      "        [[ 1.7980-0.1506j, -1.1110+0.0184j, -0.3771+1.0635j, -1.2193+0.3169j],\n",
      "         [ 0.8660+0.4287j, -0.3461+0.3921j,  0.1221-0.0784j,  0.4920-0.0571j]],\n",
      "\n",
      "        [[ 1.7646-0.1076j, -0.4875-0.9969j,  1.2998+0.5949j,  0.2569-0.9195j],\n",
      "         [ 0.6145-0.2512j,  1.3982+0.5809j,  0.4404-0.4569j,  0.1865+0.3349j]]])\n",
      "\n",
      "加了AWGN后的输出向量:\n",
      "tensor([[ 1.5648+1.0159j, -1.0795+1.5959j],\n",
      "        [-0.9591-1.0191j,  1.0271+0.3200j],\n",
      "        [ 4.0218+1.9995j,  0.1728-0.3820j]])\n"
     ]
    }
   ],
   "source": [
    "def test_flat_fading_channel():\n",
    "    # 测试代码\n",
    "    num_tx_ant = 4\n",
    "    num_rx_ant = 2\n",
    "    batch_size = 3\n",
    "\n",
    "    # 生成输入数据\n",
    "    x = torch.randn(batch_size, num_tx_ant, dtype=torch.cfloat)\n",
    "\n",
    "    # 定义噪声功率\n",
    "    no = torch.tensor(0.1, dtype=torch.float32)\n",
    "\n",
    "    # 初始化 FlatFadingChannel 类\n",
    "    flat_fading_channel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\n",
    "\n",
    "    # 进行前向传播\n",
    "    y, h = flat_fading_channel((x, no))\n",
    "\n",
    "    # 打印输出结果\n",
    "    print(\"传输向量:\")\n",
    "    print(x)\n",
    "    print(\"\\n信道矩阵:\")\n",
    "    print(h)\n",
    "    print(\"\\n加了AWGN后的输出向量:\")\n",
    "    print(y)\n",
    "test_flat_fading_channel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
