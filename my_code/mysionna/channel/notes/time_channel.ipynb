{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sionna.channel import RayleighBlockFading\n",
    "from sionna.channel import GenerateTimeChannel, ApplyTimeChannel\n",
    "from sionna.channel.utils import time_lag_discrete_time_channel\n",
    "class TimeChannel(tf.keras.layers.Layer):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"TimeChannel(channel_model, bandwidth, num_time_samples, maximum_delay_spread=3e-6, l_min=None, l_max=None, normalize_channel=False, add_awgn=True, return_channel=False, dtype=tf.complex64, **kwargs)\n",
    "\n",
    "    Generate channel responses and apply them to channel inputs in the time domain.\n",
    "\n",
    "    This class inherits from the Keras `Layer` class and can be used as layer\n",
    "    in a Keras model.\n",
    "\n",
    "    The channel output consists of ``num_time_samples`` + ``l_max`` - ``l_min``\n",
    "    time samples, as it is the result of filtering the channel input of length\n",
    "    ``num_time_samples`` with the time-variant channel filter  of length\n",
    "    ``l_max`` - ``l_min`` + 1. In the case of a single-input single-output link and given a sequence of channel\n",
    "    inputs :math:`x_0,\\cdots,x_{N_B}`, where :math:`N_B` is ``num_time_samples``, this\n",
    "    layer outputs\n",
    "\n",
    "    .. math::\n",
    "        y_b = \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b\n",
    "\n",
    "    where :math:`L_{\\text{min}}` corresponds ``l_min``, :math:`L_{\\text{max}}` to ``l_max``, :math:`w_b` to\n",
    "    the additive noise, and :math:`\\bar{h}_{b,\\ell}` to the\n",
    "    :math:`\\ell^{th}` tap of the :math:`b^{th}` channel sample.\n",
    "    This layer outputs :math:`y_b` for :math:`b` ranging from :math:`L_{\\text{min}}` to\n",
    "    :math:`N_B + L_{\\text{max}} - 1`, and :math:`x_{b}` is set to 0 for :math:`b < 0` or :math:`b \\geq N_B`.\n",
    "    The channel taps :math:`\\bar{h}_{b,\\ell}` are computed assuming a sinc filter\n",
    "    is used for pulse shaping and receive filtering. Therefore, given a channel impulse response\n",
    "    :math:`(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1`, generated by the ``channel_model``,\n",
    "    the channel taps are computed as follows:\n",
    "\n",
    "    .. math::\n",
    "        \\bar{h}_{b, \\ell}\n",
    "        = \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n",
    "            \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n",
    "\n",
    "    for :math:`\\ell` ranging from ``l_min`` to ``l_max``, and where :math:`W` is\n",
    "    the ``bandwidth``.\n",
    "\n",
    "    For multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    channel_model : :class:`~sionna.channel.ChannelModel` object\n",
    "        An instance of a :class:`~sionna.channel.ChannelModel`, such as\n",
    "        :class:`~sionna.channel.RayleighBlockFading` or\n",
    "        :class:`~sionna.channel.tr38901.UMi`.\n",
    "\n",
    "    bandwidth : float\n",
    "        Bandwidth (:math:`W`) [Hz]\n",
    "\n",
    "    num_time_samples : int\n",
    "        Number of time samples forming the channel input (:math:`N_B`)\n",
    "\n",
    "    maximum_delay_spread : float\n",
    "        Maximum delay spread [s].\n",
    "        Used to compute the default value of ``l_max`` if ``l_max`` is set to\n",
    "        `None`. If a value is given for ``l_max``, this parameter is not used.\n",
    "        It defaults to 3us, which was found\n",
    "        to be large enough to include most significant paths with all channel\n",
    "        models included in Sionna assuming a nominal delay spread of 100ns.\n",
    "\n",
    "    l_min : int\n",
    "        Smallest time-lag for the discrete complex baseband channel (:math:`L_{\\text{min}}`).\n",
    "        If set to `None`, defaults to the value given by :func:`time_lag_discrete_time_channel`.\n",
    "\n",
    "    l_max : int\n",
    "        Largest time-lag for the discrete complex baseband channel (:math:`L_{\\text{max}}`).\n",
    "        If set to `None`, it is computed from ``bandwidth`` and ``maximum_delay_spread``\n",
    "        using :func:`time_lag_discrete_time_channel`. If it is not set to `None`,\n",
    "        then the parameter ``maximum_delay_spread`` is not used.\n",
    "\n",
    "    add_awgn : bool\n",
    "        If set to `False`, no white Gaussian noise is added.\n",
    "        Defaults to `True`.\n",
    "\n",
    "    normalize_channel : bool\n",
    "        If set to `True`, the channel is normalized over the block size\n",
    "        to ensure unit average energy per time step. Defaults to `False`.\n",
    "\n",
    "    return_channel : bool\n",
    "        If set to `True`, the channel response is returned in addition to the\n",
    "        channel output. Defaults to `False`.\n",
    "\n",
    "    dtype : tf.DType\n",
    "        Complex datatype to use for internal processing and output.\n",
    "        Defaults to `tf.complex64`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "\n",
    "    (x, no) or x:\n",
    "        Tuple or Tensor:\n",
    "\n",
    "    x :  [batch size, num_tx, num_tx_ant, num_time_samples], tf.complex\n",
    "        Channel inputs\n",
    "\n",
    "    no : Scalar or Tensor, tf.float\n",
    "        Scalar or tensor whose shape can be broadcast to the shape of the\n",
    "        channel outputs: [batch size, num_rx, num_rx_ant, num_time_samples].\n",
    "        Only required if ``add_awgn`` is set to `True`.\n",
    "        The noise power ``no`` is per complex dimension. If ``no`` is a scalar,\n",
    "        noise of the same variance will be added to the outputs.\n",
    "        If ``no`` is a tensor, it must have a shape that can be broadcast to\n",
    "        the shape of the channel outputs. This allows, e.g., adding noise of\n",
    "        different variance to each example in a batch. If ``no`` has a lower\n",
    "        rank than the channel outputs, then ``no`` will be broadcast to the\n",
    "        shape of the channel outputs by adding dummy dimensions after the last\n",
    "        axis.\n",
    "\n",
    "    Output\n",
    "    -------\n",
    "    y : [batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], tf.complex\n",
    "        Channel outputs\n",
    "        The channel output consists of ``num_time_samples`` + ``l_max`` - ``l_min``\n",
    "        time samples, as it is the result of filtering the channel input of length\n",
    "        ``num_time_samples`` with the time-variant channel filter  of length\n",
    "        ``l_max`` - ``l_min`` + 1.\n",
    "\n",
    "    h_time : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex\n",
    "        (Optional) Channel responses. Returned only if ``return_channel``\n",
    "        is set to `True`.\n",
    "        For each batch example, ``num_time_samples`` + ``l_max`` - ``l_min`` time\n",
    "        steps of the channel realizations are generated to filter the channel input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channel_model, bandwidth, num_time_samples,\n",
    "                 maximum_delay_spread=3e-6, l_min=None, l_max=None,\n",
    "                 normalize_channel=False, add_awgn=True, return_channel=False,\n",
    "                 dtype=tf.complex64, **kwargs):\n",
    "\n",
    "        super().__init__(trainable=False, dtype=dtype, **kwargs)\n",
    "\n",
    "        # Setting l_min and l_max to default values if not given by the user\n",
    "        l_min_default, l_max_default = time_lag_discrete_time_channel(bandwidth,\n",
    "                                                            maximum_delay_spread)\n",
    "        if l_min is None:\n",
    "            l_min = l_min_default\n",
    "        if l_max is None:\n",
    "            l_max = l_max_default\n",
    "\n",
    "        self._cir_sampler = channel_model\n",
    "        self._bandwidth = bandwidth\n",
    "        self._num_time_steps = num_time_samples\n",
    "        self._l_min = l_min\n",
    "        self._l_max = l_max\n",
    "        self._l_tot = l_max-l_min+1\n",
    "        self._normalize_channel = normalize_channel\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "\n",
    "    def build(self, input_shape): #pylint: disable=unused-argument\n",
    "\n",
    "        self._generate_channel = GenerateTimeChannel(self._cir_sampler,\n",
    "                                                     self._bandwidth,\n",
    "                                                     self._num_time_steps,\n",
    "                                                     self._l_min,\n",
    "                                                     self._l_max,\n",
    "                                                     self._normalize_channel)\n",
    "        self._apply_channel = ApplyTimeChannel( self._num_time_steps,\n",
    "                                                self._l_tot,\n",
    "                                                self._add_awgn,\n",
    "                                                tf.as_dtype(self.dtype))\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "\n",
    "        h_time = self._generate_channel(tf.shape(x)[0])\n",
    "        if self._add_awgn:\n",
    "            y = self._apply_channel([x, h_time, no])\n",
    "        else:\n",
    "            y = self._apply_channel([x, h_time])\n",
    "\n",
    "        if self._return_channel:\n",
    "            return y, h_time\n",
    "        else:\n",
    "            return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 x:\n",
      "tf.Tensor(\n",
      "[[[[-1.6753638 +0.30501944j  0.9829815 -1.004707j\n",
      "    -0.43382445+0.07296482j  1.1888292 -0.36816195j\n",
      "     1.6569929 -0.09330415j  0.1253348 +0.636844j\n",
      "     1.7838709 +0.77345973j  1.0827578 +1.0736915j\n",
      "     0.37426516+1.2467664j   0.66080546+0.3196252j ]]]\n",
      "\n",
      "\n",
      " [[[ 0.28745562-1.0514264j  -0.51575756-1.7484419j\n",
      "     0.15059014-0.614426j    0.7247111 -0.4713373j\n",
      "    -0.31492364-0.7146405j   0.56923485-0.1777594j\n",
      "    -0.7117779 -0.7438315j   1.0640773 -0.8405494j\n",
      "    -0.25746384+0.17083897j  0.17408323-0.05860179j]]]], shape=(2, 1, 1, 10), dtype=complex64)\n",
      "输出 y:\n",
      "tf.Tensor(\n",
      "[[[[-0.01393137+3.72437626e-01j  0.05722164-7.69637234e-04j\n",
      "    -0.16455391+4.74788338e-01j  0.31704393+2.28539854e-02j\n",
      "     0.1984425 +5.76564819e-02j  0.11931367+2.00089335e-01j\n",
      "     0.92348546-5.00796080e-01j -0.26727003+1.13903093e+00j\n",
      "     0.1435872 +5.95897436e-05j -0.70640695+2.83713162e-01j\n",
      "    -0.84751976+1.62441507e-01j -0.31377095-3.85421813e-01j\n",
      "    -0.6261524 +5.68508580e-02j -0.6775814 -5.32410502e-01j\n",
      "    -0.4170916 -5.71045578e-01j -0.32294974-4.85907853e-01j\n",
      "    -0.57662576+1.32019995e-02j  0.19523066+3.85147899e-01j\n",
      "    -0.17882325+1.20589901e-02j  0.3266136 +3.47003102e-01j\n",
      "    -0.14408758+3.70224193e-02j -0.17371638-2.94088367e-02j\n",
      "     0.04182488+9.77224112e-02j  0.43601874-2.99139649e-01j\n",
      "    -0.10433871+1.51364952e-01j]]]\n",
      "\n",
      "\n",
      " [[[ 0.03101462+1.26300827e-01j  0.4037928 -5.09416386e-02j\n",
      "    -0.16261254+7.43196905e-03j  0.19719158-4.52693999e-02j\n",
      "    -0.24433717-3.53642166e-01j -0.19088931-5.47003634e-02j\n",
      "     1.3626056 -5.20694435e-01j  0.7170487 -2.07439232e+00j\n",
      "     0.68463796-5.03268659e-01j  1.0858041 +1.15137838e-01j\n",
      "     0.34299982-6.88885689e-01j  0.9232385 +4.33848947e-02j\n",
      "     0.23537728-1.60932696e+00j  2.0821261 -4.26526591e-02j\n",
      "    -0.74351156+1.21050691e-02j  0.15386415+1.74527794e-01j\n",
      "    -0.30795306+1.75512046e-01j  0.02763597+4.15683389e-02j\n",
      "     0.35724482-1.15133347e-02j  0.08049877+2.52448738e-01j\n",
      "    -0.03756407+9.33071896e-02j  0.14813685-1.37067765e-01j\n",
      "     0.3868328 +5.53904027e-02j  0.26829502+2.34162033e-01j\n",
      "    -0.00468901+1.10665426e-01j]]]], shape=(2, 1, 1, 25), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的测试代码\n",
    "def test_time_channel():\n",
    "    batch_size = 2\n",
    "    num_tx = 1\n",
    "    num_tx_ant = 1\n",
    "    num_rx = 1\n",
    "    num_rx_ant = 1\n",
    "    num_time_samples = 10\n",
    "    bandwidth = 1e6\n",
    "\n",
    "    # 模拟的channel_model，可以使用任何合适的模型实例化\n",
    "    channel_model = RayleighBlockFading(num_rx,num_rx_ant,num_tx,num_tx_ant,dtype=tf.complex64)\n",
    "\n",
    "    # 实例化 TimeChannel\n",
    "    time_channel = TimeChannel(channel_model, bandwidth, num_time_samples)\n",
    "\n",
    "    # 生成一些随机输入数据\n",
    "    x = tf.complex(\n",
    "        tf.random.normal([batch_size, num_tx, num_tx_ant, num_time_samples]),\n",
    "        tf.random.normal([batch_size, num_tx, num_tx_ant, num_time_samples])\n",
    "    )\n",
    "    no = tf.constant(0.1, dtype=tf.float32)\n",
    "\n",
    "    # 调用 TimeChannel\n",
    "    y = time_channel((x, no))\n",
    "\n",
    "    print(\"输入 x:\")\n",
    "    print(x)\n",
    "    print(\"输出 y:\")\n",
    "    print(y)\n",
    "\n",
    "# 运行测试代码\n",
    "test_time_channel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from my_code.mysionna.channel.torch_version.generate_time_channel import GenerateTimeChannel\n",
    "from my_code.mysionna.channel.torch_version.apply_time_channel import ApplyTimeChannel\n",
    "\n",
    "from my_code.mysionna.channel.torch_version.rayleigh_block_fading import RayleighBlockFading\n",
    "\n",
    "from my_code.mysionna.channel.torch_version.utils import time_lag_discrete_time_channel\n",
    "class TimeChannel(nn.Module):\n",
    "    r\"\"\"TimeChannel(channel_model, bandwidth, num_time_samples, maximum_delay_spread=3e-6, l_min=None, l_max=None, normalize_channel=False, add_awgn=True, return_channel=False, dtype=torch.complex64)\n",
    "\n",
    "    Generate channel responses and apply them to channel inputs in the time domain.\n",
    "\n",
    "    This class inherits from the PyTorch `nn.Module` class and can be used as a layer\n",
    "    in a PyTorch model.\n",
    "\n",
    "    The channel output consists of `num_time_samples` + `l_max` - `l_min`\n",
    "    time samples, as it is the result of filtering the channel input of length\n",
    "    `num_time_samples` with the time-variant channel filter  of length\n",
    "    `l_max` - `l_min` + 1. In the case of a single-input single-output link and given a sequence of channel\n",
    "    inputs `x_0, ..., x_{N_B}`, where `N_B` is `num_time_samples`, this\n",
    "    layer outputs:\n",
    "\n",
    "    .. math::\n",
    "        y_b = \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b\n",
    "\n",
    "    where `L_{\\text{min}}` corresponds `l_min`, `L_{\\text{max}}` to `l_max`, `w_b` to\n",
    "    the additive noise, and `\\bar{h}_{b,\\ell}` to the\n",
    "    `\\ell^{th}` tap of the `b^{th}` channel sample.\n",
    "    This layer outputs `y_b` for `b` ranging from `L_{\\text{min}}` to\n",
    "    `N_B + L_{\\text{max}} - 1`, and `x_{b}` is set to 0 for `b < 0` or `b \\geq N_B`.\n",
    "    The channel taps `\\bar{h}_{b,\\ell}` are computed assuming a sinc filter\n",
    "    is used for pulse shaping and receive filtering. Therefore, given a channel impulse response\n",
    "    `(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1`, generated by the `channel_model`,\n",
    "    the channel taps are computed as follows:\n",
    "\n",
    "    .. math::\n",
    "        \\bar{h}_{b, \\ell}\n",
    "        = \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n",
    "            \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n",
    "\n",
    "    for `\\ell` ranging from `l_min` to `l_max`, and where `W` is\n",
    "    the `bandwidth`.\n",
    "\n",
    "    For multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    channel_model : object\n",
    "        An instance of a ChannelModel, such as RayleighBlockFading or UMi.\n",
    "\n",
    "    bandwidth : float\n",
    "        Bandwidth (W) [Hz]\n",
    "\n",
    "    num_time_samples : int\n",
    "        Number of time samples forming the channel input (N_B)\n",
    "\n",
    "    maximum_delay_spread : float\n",
    "        Maximum delay spread [s].\n",
    "        Used to compute the default value of `l_max` if `l_max` is set to `None`. If a value is given for `l_max`, this parameter is not used.\n",
    "        It defaults to 3us, which was found\n",
    "        to be large enough to include most significant paths with all channel\n",
    "        models included in Sionna assuming a nominal delay spread of 100ns.\n",
    "\n",
    "    l_min : int\n",
    "        Smallest time-lag for the discrete complex baseband channel (L_{\\text{min}}).\n",
    "        If set to `None`, defaults to the value given by `time_lag_discrete_time_channel`.\n",
    "\n",
    "    l_max : int\n",
    "        Largest time-lag for the discrete complex baseband channel (L_{\\text{max}}).\n",
    "        If set to `None`, it is computed from `bandwidth` and `maximum_delay_spread`\n",
    "        using `time_lag_discrete_time_channel`. If it is not set to `None`,\n",
    "        then the parameter `maximum_delay_spread` is not used.\n",
    "\n",
    "    add_awgn : bool\n",
    "        If set to `False`, no white Gaussian noise is added.\n",
    "        Defaults to `True`.\n",
    "\n",
    "    normalize_channel : bool\n",
    "        If set to `True`, the channel is normalized over the block size\n",
    "        to ensure unit average energy per time step. Defaults to `False`.\n",
    "\n",
    "    return_channel : bool\n",
    "        If set to `True`, the channel response is returned in addition to the\n",
    "        channel output. Defaults to `False`.\n",
    "\n",
    "    dtype : torch.dtype\n",
    "        Complex datatype to use for internal processing and output.\n",
    "        Defaults to `torch.complex64`.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    (x, no) or x:\n",
    "        Tuple or Tensor:\n",
    "\n",
    "    x : [batch size, num_tx, num_tx_ant, num_time_samples], torch.complex64\n",
    "        Channel inputs\n",
    "\n",
    "    no : Scalar or Tensor, torch.float\n",
    "        Scalar or tensor whose shape can be broadcast to the shape of the\n",
    "        channel outputs: [batch size, num_rx, num_rx_ant, num_time_samples].\n",
    "        Only required if `add_awgn` is set to `True`.\n",
    "        The noise power `no` is per complex dimension. If `no` is a scalar,\n",
    "        noise of the same variance will be added to the outputs.\n",
    "        If `no` is a tensor, it must have a shape that can be broadcast to\n",
    "        the shape of the channel outputs. This allows, e.g., adding noise of\n",
    "        different variance to each example in a batch. If `no` has a lower\n",
    "        rank than `no` will be broadcast to the shape of the channel outputs by adding dummy dimensions after the last axis.\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    y : [batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], torch.complex64\n",
    "        Channel outputs\n",
    "        The channel output consists of `num_time_samples` + `l_max` - `l_min`\n",
    "        time samples, as it is the result of filtering the channel input of length\n",
    "        `num_time_samples` with the time-variant channel filter of length\n",
    "        `l_max` - `l_min` + 1.\n",
    "\n",
    "    h_time : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], torch.complex64\n",
    "        (Optional) Channel responses. Returned only if `return_channel`\n",
    "        is set to `True`.\n",
    "        For each batch example, `num_time_samples` + `l_max` - `l_min` time\n",
    "        steps of the channel realizations are generated to filter the channel input.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, channel_model, bandwidth, num_time_samples,\n",
    "                 maximum_delay_spread=3e-6, l_min=None, l_max=None,\n",
    "                 normalize_channel=False, add_awgn=True, return_channel=False,\n",
    "                 dtype=torch.complex64, **kwargs) :\n",
    "        super().__init__()\n",
    "\n",
    "        # Setting l_min and l_max to default values if not given by the user\n",
    "        l_min_default, l_max_default = time_lag_discrete_time_channel(bandwidth,\n",
    "                                                            maximum_delay_spread)\n",
    "        if l_min is None:\n",
    "            l_min = l_min_default\n",
    "        if l_max is None:\n",
    "            l_max = l_max_default\n",
    "\n",
    "        self._cir_sampler = channel_model\n",
    "        self._bandwidth = bandwidth\n",
    "        self._num_time_steps = num_time_samples\n",
    "        self._l_min = l_min\n",
    "        self._l_max = l_max\n",
    "        self._l_tot = l_max-l_min+1\n",
    "        self._normalize_channel = normalize_channel\n",
    "        self._add_awgn = add_awgn\n",
    "        self._return_channel = return_channel\n",
    "\n",
    "        self._generate_channel = GenerateTimeChannel(self._cir_sampler,\n",
    "                                                     self._bandwidth,\n",
    "                                                     self._num_time_steps,\n",
    "                                                     self._l_min,\n",
    "                                                     self._l_max,\n",
    "                                                     self._normalize_channel)\n",
    "        self._apply_channel = ApplyTimeChannel( self._num_time_steps,\n",
    "                                                self._l_tot,\n",
    "                                                self._add_awgn,\n",
    "                                                dtype=dtype)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "\n",
    "        if self._add_awgn:\n",
    "            x, no = inputs\n",
    "        else:\n",
    "            x = inputs\n",
    "        h_time = self._generate_channel(x.shape[0])\n",
    "        if self._add_awgn:\n",
    "            y = self._apply_channel([x, h_time, no])\n",
    "        else:\n",
    "            y = self._apply_channel([x, h_time])\n",
    "        \n",
    "        if self._return_channel:\n",
    "            return y, h_time\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入 x:\n",
      "tensor([[[[-0.9559-0.0227j, -0.5990+0.8445j,  1.1011+0.6300j,  2.0859-0.1052j,\n",
      "           -0.4886-1.1621j, -0.3858+1.2630j,  0.9367+0.8431j, -0.0325-0.5966j,\n",
      "            0.5165-0.0517j, -0.2132+0.9363j]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2713+0.4352j,  0.0772+0.4346j, -0.5520-0.5838j,  1.0532-0.5001j,\n",
      "            0.8292+0.4117j,  0.4373+0.5244j,  0.6670+0.9093j, -0.4013-0.3798j,\n",
      "            0.2102-0.7558j,  1.6349+1.5615j]]]])\n",
      "torch.Size([2, 1, 1, 10])\n",
      "输出 y:\n",
      "tensor([[[[ 0.3012-1.0980e-01j, -0.2726+4.8713e-02j,  0.2416-2.3518e-02j,\n",
      "           -0.0292+1.1536e-01j, -0.0865-1.7738e-01j, -0.0549-1.3744e-01j,\n",
      "           -0.1470-4.8799e-01j, -0.4562-4.7662e-01j, -0.3636+1.0698e+00j,\n",
      "           -0.2905+1.3253e+00j,  1.1085-3.2719e-01j, -0.6763-4.7157e-01j,\n",
      "           -0.8422+8.8590e-01j, -0.0248-5.1019e-02j, -0.1512+2.6981e-01j,\n",
      "           -0.3043-4.1496e-01j,  0.0319+4.1290e-01j, -0.0491+6.1644e-02j,\n",
      "            0.3861+1.3316e-02j,  0.0763-1.8835e-01j,  0.0332-7.3446e-02j,\n",
      "            0.4344+8.7056e-02j, -0.0888+6.3539e-02j,  0.2776-1.3102e-01j,\n",
      "            0.3086+1.3477e-01j]]],\n",
      "\n",
      "\n",
      "        [[[-0.2959+6.0259e-02j, -0.0727-2.0320e-01j, -0.0964-7.3627e-02j,\n",
      "            0.5113+4.2855e-02j, -0.1240-2.8508e-01j,  0.3114+4.4376e-02j,\n",
      "            0.0719-1.0261e+00j,  0.2850-7.3081e-01j,  0.0960+1.0677e+00j,\n",
      "           -1.9317-4.6398e-01j, -1.2080-1.5344e+00j, -0.2779-1.1070e+00j,\n",
      "           -0.5797-2.4022e+00j,  0.1317+1.0124e+00j, -1.3327+8.0728e-01j,\n",
      "           -1.2672-3.8842e+00j, -0.1531+1.3306e-01j,  0.2417+1.5482e-01j,\n",
      "           -0.0820+9.2931e-02j, -0.0090-8.3803e-02j, -0.0146-2.0813e-01j,\n",
      "           -0.0372+5.0905e-01j,  0.2270+3.0384e-03j, -0.3433-1.9026e-01j,\n",
      "            0.2043-1.8994e-01j]]]])\n",
      "torch.Size([2, 1, 1, 25])\n"
     ]
    }
   ],
   "source": [
    "# 定义一个简单的测试代码\n",
    "def test_time_channel():\n",
    "    batch_size = 2\n",
    "    num_tx = 1\n",
    "    num_tx_ant = 1\n",
    "    num_rx = 1\n",
    "    num_rx_ant = 1\n",
    "    num_time_samples = 10\n",
    "    bandwidth = 1e6\n",
    "\n",
    "    # 模拟的channel_model，可以使用任何合适的模型实例化\n",
    "    channel_model = RayleighBlockFading(num_rx,num_rx_ant,num_tx,num_tx_ant,dtype=torch.complex64)\n",
    "\n",
    "    # 实例化 TimeChannel\n",
    "    time_channel = TimeChannel(channel_model, bandwidth, num_time_samples)\n",
    "\n",
    "    # 生成一些随机输入数据\n",
    "    x = torch.complex(\n",
    "        torch.randn([batch_size, num_tx, num_tx_ant, num_time_samples]),\n",
    "        torch.randn([batch_size, num_tx, num_tx_ant, num_time_samples])\n",
    "    )\n",
    "    no = torch.tensor(0.1, dtype=torch.float32)\n",
    "\n",
    "    # 调用 TimeChannel\n",
    "    y = time_channel((x, no))\n",
    "\n",
    "    print(\"输入 x:\")\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    print(\"输出 y:\")\n",
    "    print(y)\n",
    "    print(y.shape)\n",
    "\n",
    "# 运行测试代码\n",
    "test_time_channel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
