{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 10:39:15.986268: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-19 10:39:15.986317: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-19 10:39:15.988118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-19 10:39:15.996705: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-19 10:39:17.255052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[0.4503, 0.4728, 0.7179],\n",
      "        [0.4728, 0.8853, 1.0855],\n",
      "        [0.7179, 1.0855, 1.5643]])\n",
      "Square root of the tensor:\n",
      " tensor([[0.5082, 0.2051, 0.3873],\n",
      "        [0.2051, 0.7193, 0.5708],\n",
      "        [0.3873, 0.5708, 1.0433]])\n",
      "Product of sqrt and its transpose:\n",
      " tensor([[0.4503, 0.4728, 0.7179],\n",
      "        [0.4728, 0.8853, 1.0855],\n",
      "        [0.7179, 1.0855, 1.5643]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 10:39:18.694683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18425 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import my_code.mysionna as sn\n",
    "import tensorflow as tf\n",
    "from my_code.mysionna.utils import GLOBAL_SEED_NUMBER\n",
    "import numpy as np\n",
    "\n",
    "def matrix_sqrt(tensor):\n",
    "    r\"\"\" Computes the square root of a matrix.\n",
    "\n",
    "    Given a batch of Hermitian positive semi-definite matrices\n",
    "    :math:`\\mathbf{A}`, returns matrices :math:`\\mathbf{B}`,\n",
    "    such that :math:`\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}`.\n",
    "\n",
    "    The two inner dimensions are assumed to correspond to the matrix rows\n",
    "    and columns, respectively.\n",
    "\n",
    "    Args:\n",
    "        tensor ([..., M, M]) : A tensor of rank greater than or equal\n",
    "            to two.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of the same shape and type as ``tensor`` containing\n",
    "        the matrix square root of its last two dimensions.\n",
    "    \"\"\"\n",
    "    if sn.config.xla_compat and not tensor.is_grad_enabled():\n",
    "        s, u = torch.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = torch.abs(s)\n",
    "        s = torch.sqrt(s)\n",
    "        s = s.type(dtype=u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = s.unsqueeze(-2)\n",
    "        return torch.matmul(u * s, torch.conj(torch.transpose(u, -2, -1)))\n",
    "    else:\n",
    "        s, u = torch.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = torch.abs(s)\n",
    "        s = torch.sqrt(s)\n",
    "        s = s.type(dtype=u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = s.unsqueeze(-2)\n",
    "        return torch.matmul(u * s, torch.conj(torch.transpose(u, -2, -1)))\n",
    "# Example usage:\n",
    "tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "tensor_tf = tf.random.uniform(shape=[3,3])\n",
    "tensor_np = tensor_tf.numpy()\n",
    "tensor = torch.from_numpy(tensor_np)\n",
    "# tensor = torch.randn(3, 3, dtype=torch.float64)\n",
    "tensor = tensor @ tensor.T  # Make it positive semi-definite\n",
    "\n",
    "sqrt_tensor = matrix_sqrt(tensor)\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "print(\"Square root of the tensor:\\n\", sqrt_tensor)\n",
    "print(\"Product of sqrt and its transpose:\\n\", sqrt_tensor @ sqrt_tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix A:\n",
      " tensor([[4.+0.j, 1.+1.j],\n",
      "        [1.-1.j, 3.+0.j]])\n",
      "Matrix Square Root B:\n",
      " tensor([[1.9621+0.0000j, 0.2740+0.2740j],\n",
      "        [0.2740-0.2740j, 1.6882+0.0000j]])\n",
      "Reconstructed Matrix A:\n",
      " tensor([[4.0000+8.2587e-10j, 1.0000+1.0000e+00j],\n",
      "        [1.0000-1.0000e+00j, 3.0000+6.0175e-10j]])\n"
     ]
    }
   ],
   "source": [
    "# 测试例子\n",
    "def test_matrix_sqrt_torch():\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    B = matrix_sqrt(A)\n",
    "\n",
    "    # 验证 B * B^H 是否等于 A\n",
    "    reconstructed_A = torch.matmul(B, B.transpose(-2, -1).conj())\n",
    "    print(\"Original Matrix A:\\n\", A)\n",
    "    print(\"Matrix Square Root B:\\n\", B)\n",
    "    print(\"Reconstructed Matrix A:\\n\", reconstructed_A)\n",
    "\n",
    "test_matrix_sqrt_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 2, 2, 2, 1, 10)\n",
      "(4, 2, 2, 1)\n",
      "Original Matrix A:\n",
      " [[4.+0.j 1.+1.j]\n",
      " [1.-1.j 3.+0.j]]\n",
      "Matrix Square Root B:\n",
      " [[1.9621162 -2.4636604e-09j 0.27395147+2.7395147e-01j]\n",
      " [0.27395147-2.7395147e-01j 1.688165  +0.0000000e+00j]]\n",
      "Reconstructed Matrix A:\n",
      " [[3.999999  -6.0174798e-10j 0.99999994+9.9999994e-01j]\n",
      " [0.99999994-9.9999994e-01j 2.9999998 -6.0174798e-10j]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sionna as sn\n",
    "def matrix_sqrt(tensor):\n",
    "    r\"\"\" Computes the square root of a matrix.\n",
    "\n",
    "    Given a batch of Hermitian positive semi-definite matrices\n",
    "    :math:`\\mathbf{A}`, returns matrices :math:`\\mathbf{B}`,\n",
    "    such that :math:`\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}`.\n",
    "\n",
    "    The two inner dimensions are assumed to correspond to the matrix rows\n",
    "    and columns, respectively.\n",
    "\n",
    "    Args:\n",
    "        tensor ([..., M, M]) : A tensor of rank greater than or equal\n",
    "            to two.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of the same shape and type as ``tensor`` containing\n",
    "        the matrix square root of its last two dimensions.\n",
    "\n",
    "    Note:\n",
    "        If you want to use this function in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.config.xla_compat`.\n",
    "    \"\"\"\n",
    "    if sn.config.xla_compat and not tf.executing_eagerly():\n",
    "        s, u = tf.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = tf.abs(s)\n",
    "        s = tf.sqrt(s)\n",
    "        s = tf.cast(s, u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = tf.expand_dims(s, -2)\n",
    "        return tf.matmul(u*s, u, adjoint_b=True)\n",
    "    else:\n",
    "        return tf.linalg.sqrtm(tensor)\n",
    "\n",
    "# 测试例子\n",
    "def test_matrix_sqrt_tf():\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = tf.constant([[4 + 0j, 1 + 1j], [1 - 1j, 3 + 0j]], dtype=tf.complex64)\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    B = matrix_sqrt(A)\n",
    "\n",
    "    # 验证 B * B^H 是否等于 A\n",
    "    reconstructed_A = tf.matmul(B, tf.linalg.adjoint(B))\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"Original Matrix A:\\n\", A.numpy())\n",
    "    print(\"Matrix Square Root B:\\n\", B.numpy())\n",
    "    print(\"Reconstructed Matrix A:\\n\", reconstructed_A.numpy())\n",
    "\n",
    "test_matrix_sqrt_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " [[0.450283915 0.472771168 0.717919]\n",
      " [0.472771168 0.885265 1.08552921]\n",
      " [0.717919 1.08552921 1.56428695]]\n",
      "Square root of the tensor:\n",
      " [[0.508175135 0.205055624 0.387291431]\n",
      " [0.205055609 0.719296813 0.570814967]\n",
      " [0.387291431 0.570815086 1.04329455]]\n",
      "Product of sqrt and its transpose:\n",
      " [[0.450284421 0.472771764 0.717919767]\n",
      " [0.472771764 0.88526547 1.0855298]\n",
      " [0.717919767 1.0855298 1.56428814]]\n"
     ]
    }
   ],
   "source": [
    "# 测试例子\n",
    "def test_matrix_sqrt_tf():\n",
    "    # 创建随机矩阵并使其为正半定矩阵\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "    tensor = tf.random.uniform(shape=[3,3])\n",
    "    tensor = tf.matmul(tensor, tensor, transpose_b=True)  # 使其为正半定矩阵\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    sqrt_tensor = matrix_sqrt(tensor)\n",
    "\n",
    "    # 验证 sqrt_tensor * sqrt_tensor^T 是否等于原始矩阵\n",
    "    reconstructed_tensor = tf.matmul(sqrt_tensor, sqrt_tensor, transpose_b=True)\n",
    "    \n",
    "    # 打印结果\n",
    "    tf.print(\"Original tensor:\\n\", tensor)\n",
    "    tf.print(\"Square root of the tensor:\\n\", sqrt_tensor)\n",
    "    tf.print(\"Product of sqrt and its transpose:\\n\", reconstructed_tensor)\n",
    "\n",
    "test_matrix_sqrt_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "h= torch.rand(size=(3,4,6,8,9))\n",
    "print(h.dim())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "h = tf.random.uniform(shape=[3,4,6,8,9])\n",
    "print(tf.rank(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncorrelated channel coefficients:\n",
      " tensor([[ 0.1605+0.6497j, -1.6598+0.3279j],\n",
      "        [-1.2321-0.7520j,  0.5972-0.2143j]])\n",
      "Correlated channel coefficients:\n",
      " tensor([[-0.0706+2.5730j, -4.1521+1.0968j],\n",
      "        [-3.2707-2.4010j,  1.2397-1.2803j]])\n",
      "Input h:\n",
      " tensor([[ 0.1605+0.6497j, -1.6598+0.3279j, -1.2321-0.7520j],\n",
      "        [ 0.5972-0.2143j,  1.0610+0.5260j, -1.3278+1.1993j],\n",
      "        [-0.2791-1.2921j, -0.0214+0.1150j, -1.5022-0.4270j],\n",
      "        [ 0.3066+0.6561j,  0.5355+0.0611j, -1.3167+0.7816j]])\n",
      "Output h_corr:\n",
      " tensor([[ 0.1605+0.6497j, -1.6598+0.3279j, -1.2321-0.7520j],\n",
      "        [ 0.5972-0.2143j,  1.0610+0.5260j, -1.3278+1.1993j],\n",
      "        [-0.2791-1.2921j, -0.0214+0.1150j, -1.5022-0.4270j],\n",
      "        [ 0.3066+0.6561j,  0.5355+0.0611j, -1.3167+0.7816j]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Various classes for spatially correlated flat-fading channels.\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from my_code.mysionna.utils import expand_to_rank,matrix_sqrt\n",
    "\n",
    "class SpatialCorrelation(ABC):\n",
    "   # pylint: disable=line-too-long\n",
    "    r\"\"\"Abstract class that defines an interface for spatial correlation functions.\n",
    "\n",
    "    The :class:`~sionna.channel.FlatFadingChannel` model can be configured with a\n",
    "    spatial correlation model.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : tf.complex\n",
    "        Tensor of arbitrary shape containing spatially uncorrelated\n",
    "        channel coefficients\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : tf.complex\n",
    "        Tensor of the same shape and dtype as ``h`` containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        return NotImplemented\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    \"\"\"Kronecker model for spatial correlation in PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_tx : [..., K, K], torch.complex\n",
    "        Tensor containing the transmit correlation matrices.\n",
    "\n",
    "    r_rx : [..., M, M], torch.complex\n",
    "        Tensor containing the receive correlation matrices.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], torch.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coefficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], torch.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        r\"\"\"Tensor containing the transmit correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_tx\n",
    "    \n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        r\"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_rx\n",
    "    \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    "    \n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt,h.dim(),0)\n",
    "            h = torch.matmul(h, r_tx_sqrt.conj().transpose(-2, -1))\n",
    "\n",
    "        \n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, h.dim(),0)\n",
    "            h = torch.matmul(r_rx_sqrt, h)\n",
    "        \n",
    "        return h\n",
    "# 测试例子\n",
    "def test_kronecker_model():\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "\n",
    "    # A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "    # B = torch.tensor([[2, 0], [0, 2]], dtype=torch.complex64)\n",
    "    \n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "    B = torch.tensor([[2, 0], [0, 2]], dtype=torch.complex64)    \n",
    "\n",
    "    # 创建 KroneckerModel 实例\n",
    "    model = KroneckerModel(r_tx=A, r_rx=B)\n",
    "\n",
    "    # 创建未相关的通道系数矩阵\n",
    "    h_tf_real = tf.random.normal(shape=[2,2],dtype=tf.float32)\n",
    "    h_tf_img = tf.random.normal(shape=[2,2],dtype=tf.float32)\n",
    "    h_np_real = h_tf_real.numpy()\n",
    "    h_np_img = h_tf_img.numpy()\n",
    "\n",
    "    h_torch_real = torch.tensor(h_np_real, dtype=torch.float32)\n",
    "    h_torch_img = torch.tensor(h_np_img, dtype=torch.float32)\n",
    "    h = torch.complex(h_torch_real,h_torch_img)\n",
    "    \n",
    "    # h = torch.randn(2, 2, dtype=torch.complex64)\n",
    "\n",
    "    # 生成相关的通道系数矩阵\n",
    "    h_corr = model(h)\n",
    "\n",
    "    print(\"Uncorrelated channel coefficients:\\n\", h)\n",
    "    print(\"Correlated channel coefficients:\\n\", h_corr)\n",
    "\n",
    "test_kronecker_model()\n",
    "\n",
    "class PerColumnModel(nn.Module):\n",
    "    r\"\"\"Per-column model for spatial correlation.\n",
    "\n",
    "    Given a batch of matrices :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`\n",
    "    and correlation matrices :math:`\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}`, k=1,\\dots,K,\n",
    "    this function will generate the output :math:`\\mathbf{H}_\\text{corr}\\in\\mathbb{C}^{M\\times K}`,\n",
    "    with columns\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathbf{h}^\\text{corr}_k = \\mathbf{R}^{\\frac12}_k \\mathbf{h}_k,\\quad k=1, \\dots, K\n",
    "\n",
    "    where :math:`\\mathbf{h}_k` is the kth column of :math:`\\mathbf{H}`.\n",
    "    Note that all :math:`\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}` must\n",
    "    be positive semi-definite.\n",
    "\n",
    "    This model is typically used to simulate a MIMO channel between multiple\n",
    "    single-antenna users and a base station with multiple antennas.\n",
    "    The resulting SIMO channel for each user has a different spatial correlation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_rx : [..., M, M], torch.complex\n",
    "        Tensor containing the receive correlation matrices. If\n",
    "        the rank of `r_rx` is smaller than that of the input `h`,\n",
    "        it will be broadcast. For a typically use of this model, `r_rx`\n",
    "        has shape [..., K, M, M], i.e., a different correlation matrix for each\n",
    "        column of `h`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], torch.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coefficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], torch.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_rx):\n",
    "        super().__init__()\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        \"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_rx\n",
    "    \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "    \n",
    "    def __call__(self, h):\n",
    "        if self._r_rx is not None:\n",
    "            h = h.transpose(-2, -1)\n",
    "            h = h.unsqueeze(-1)\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, h.dim(), 0)\n",
    "            h = torch.matmul(r_rx_sqrt, h)\n",
    "            h = h.squeeze(-1)\n",
    "            h = h.transpose(-2, -1)\n",
    "\n",
    "        return h      \n",
    "\n",
    "def test_PerColumnModel():\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "    # Define input parameters\n",
    "    M, K = 4, 3  # Dimensions of the matrices\n",
    "    h_tf = tf.complex(tf.random.normal([M, K]), tf.random.normal([M, K]))  # Random complex matrix\n",
    "    r_rx_tf = tf.complex(tf.eye(M, batch_shape=[K]), tf.zeros([K, M, M]))  # Identity matrices as correlation matrices\n",
    "\n",
    "    r_rx_np = r_rx_tf.numpy()\n",
    "    r_rx = torch.from_numpy(r_rx_np)\n",
    "\n",
    "    h_np = h_tf.numpy()\n",
    "    h = torch.from_numpy(h_np)\n",
    "    # Initialize the PerColumnModel\n",
    "    model = PerColumnModel(r_rx)\n",
    "\n",
    "    # Get the correlated channel coefficients\n",
    "    h_corr = model(h)\n",
    "\n",
    "    # Print the input and output matrices\n",
    "    print(\"Input h:\\n\", h)\n",
    "    print(\"Output h_corr:\\n\", h_corr)\n",
    "\n",
    "test_PerColumnModel()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncorrelated channel coefficients:\n",
      " tf.Tensor(\n",
      "[[ 0.16052227+0.64973587j -1.6597689 +0.32791495j]\n",
      " [-1.2321332 -0.75198144j  0.5971658 -0.21430095j]], shape=(2, 2), dtype=complex64)\n",
      "Correlated channel coefficients:\n",
      " tf.Tensor(\n",
      "[[-0.07056929+2.5730007j -4.152109  +1.0967876j]\n",
      " [-3.2706544 -2.40102j    1.2396659 -1.2803249j]], shape=(2, 2), dtype=complex64)\n",
      "----------------------------------\n",
      "Input h:\n",
      " tf.Tensor(\n",
      "[[ 0.16052227+0.64973587j -1.6597689 +0.32791495j -1.2321332 -0.75198144j]\n",
      " [ 0.5971658 -0.21430095j  1.0609884 +0.52599317j -1.3277572 +1.1992904j ]\n",
      " [-0.27911443-1.292074j   -0.02141875+0.1150163j  -1.502249  -0.42695856j]\n",
      " [ 0.3066489 +0.6561277j   0.5355358 +0.06107097j -1.3167298 +0.78159803j]], shape=(4, 3), dtype=complex64)\n",
      "Output h_corr:\n",
      " tf.Tensor(\n",
      "[[ 0.16052227+0.64973587j -1.6597689 +0.32791495j -1.2321332 -0.75198144j]\n",
      " [ 0.5971658 -0.21430095j  1.0609884 +0.52599317j -1.3277572 +1.1992904j ]\n",
      " [-0.27911443-1.292074j   -0.02141875+0.1150163j  -1.502249  -0.42695856j]\n",
      " [ 0.3066489 +0.6561277j   0.5355358 +0.06107097j -1.3167298 +0.78159803j]], shape=(4, 3), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import tensorflow as tf\n",
    "from tensorflow.experimental.numpy import swapaxes\n",
    "from sionna.utils import expand_to_rank, matrix_sqrt\n",
    "\n",
    "class SpatialCorrelation(ABC):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"Abstract class that defines an interface for spatial correlation functions.\n",
    "\n",
    "    The :class:`~sionna.channel.FlatFadingChannel` model can be configured with a\n",
    "    spatial correlation model.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : tf.complex\n",
    "        Tensor of arbitrary shape containing spatially uncorrelated\n",
    "        channel coefficients\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : tf.complex\n",
    "        Tensor of the same shape and dtype as ``h`` containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        return NotImplemented\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"Kronecker model for spatial correlation.\n",
    "\n",
    "    Given a batch of matrices :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`,\n",
    "    :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}`, and\n",
    "    :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`, this function\n",
    "    will generate the following output:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathbf{H}_\\text{corr} = \\mathbf{R}^{\\frac12}_\\text{rx} \\mathbf{H} \\mathbf{R}^{\\frac12}_\\text{tx}\n",
    "\n",
    "    Note that :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}` and :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`\n",
    "    must be positive semi-definite, such as the ones generated by\n",
    "    :meth:`~sionna.channel.exp_corr_mat`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_tx : [..., K, K], tf.complex\n",
    "        Tensor containing the transmit correlation matrices. If\n",
    "        the rank of ``r_tx`` is smaller than that of the input ``h``,\n",
    "        it will be broadcast.\n",
    "\n",
    "    r_rx : [..., M, M], tf.complex\n",
    "        Tensor containing the receive correlation matrices. If\n",
    "        the rank of ``r_rx`` is smaller than that of the input ``h``,\n",
    "        it will be broadcast.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], tf.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coeffficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], tf.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        r\"\"\"Tensor containing the transmit correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_tx\n",
    "\n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        r\"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_rx\n",
    "\n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    "\n",
    "    def __call__(self, h):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n",
    "\n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "\n",
    "        return h\n",
    "    \n",
    "def test_kronecker_model():\n",
    "    # 设置随机种子\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A_real = tf.constant([[4, 1], [1, 3]], dtype=tf.float32)\n",
    "    A_imag = tf.constant([[0, 1], [-1, 0]], dtype=tf.float32)\n",
    "    A = tf.complex(A_real, A_imag)\n",
    "\n",
    "    B_real = tf.constant([[2, 0], [0, 2]], dtype=tf.float32)\n",
    "    B_imag = tf.constant([[0, 0], [0, 0]], dtype=tf.float32)\n",
    "    B = tf.complex(B_real, B_imag)\n",
    "\n",
    "    # 创建 KroneckerModel 实例\n",
    "    model = KroneckerModel(r_tx=A, r_rx=B)\n",
    "\n",
    "    # 创建未相关的通道系数矩阵\n",
    "    h_real = tf.random.normal(shape=[2, 2], dtype=tf.float32)\n",
    "    h_imag = tf.random.normal(shape=[2, 2], dtype=tf.float32)\n",
    "    h = tf.complex(h_real, h_imag)\n",
    "\n",
    "    # 生成相关的通道系数矩阵\n",
    "    h_corr = model(h)\n",
    "\n",
    "    print(\"Uncorrelated channel coefficients:\\n\", h)\n",
    "    print(\"Correlated channel coefficients:\\n\", h_corr)\n",
    "\n",
    "test_kronecker_model()\n",
    "print(\"----------------------------------\")\n",
    "class PerColumnModel(SpatialCorrelation):\n",
    "        # pylint: disable=line-too-long\n",
    "    r\"\"\"Per-column model for spatial correlation.\n",
    "\n",
    "    Given a batch of matrices :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`\n",
    "    and correlation matrices :math:`\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}, k=1,\\dots,K`,\n",
    "    this function will generate the output :math:`\\mathbf{H}_\\text{corr}\\in\\mathbb{C}^{M\\times K}`,\n",
    "    with columns\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathbf{h}^\\text{corr}_k = \\mathbf{R}^{\\frac12}_k \\mathbf{h}_k,\\quad k=1, \\dots, K\n",
    "\n",
    "    where :math:`\\mathbf{h}_k` is the kth column of :math:`\\mathbf{H}`.\n",
    "    Note that all :math:`\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}` must\n",
    "    be positive semi-definite, such as the ones generated\n",
    "    by :meth:`~sionna.channel.one_ring_corr_mat`.\n",
    "\n",
    "    This model is typically used to simulate a MIMO channel between multiple\n",
    "    single-antenna users and a base station with multiple antennas.\n",
    "    The resulting SIMO channel for each user has a different spatial correlation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_rx : [..., M, M], tf.complex\n",
    "        Tensor containing the receive correlation matrices. If\n",
    "        the rank of ``r_rx`` is smaller than that of the input ``h``,\n",
    "        it will be broadcast. For a typically use of this model, ``r_rx``\n",
    "        has shape [..., K, M, M], i.e., a different correlation matrix for each\n",
    "        column of ``h``.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], tf.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coeffficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], tf.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_rx):\n",
    "        super().__init__()\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        \"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "\n",
    "        return self._r_rx\n",
    "\n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "\n",
    "    def __call__(self, h):\n",
    "        if self._r_rx is not None:\n",
    "            h = swapaxes(h, -2, -1)\n",
    "            h = tf.expand_dims(h, -1)\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "            h = tf.squeeze(h, -1)\n",
    "            h = swapaxes(h, -2, -1)\n",
    "\n",
    "        return h\n",
    "def test_PerColumnModel():\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "    # Define input parameters\n",
    "    M, K = 4, 3  # Dimensions of the matrices\n",
    "    h = tf.complex(tf.random.normal([M, K]), tf.random.normal([M, K]))  # Random complex matrix\n",
    "    r_rx = tf.complex(tf.eye(M, batch_shape=[K]), tf.zeros([K, M, M]))  # Identity matrices as correlation matrices\n",
    "\n",
    "    # Initialize the PerColumnModel\n",
    "    model = PerColumnModel(r_rx)\n",
    "\n",
    "    # Get the correlated channel coefficients\n",
    "    h_corr = model(h)\n",
    "\n",
    "    # Print the input and output matrices\n",
    "    print(\"Input h:\\n\", h)\n",
    "    print(\"Output h_corr:\\n\", h_corr)\n",
    "\n",
    "# Run the test\n",
    "test_PerColumnModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "tf.Tensor(\n",
      "[[[ 1.0000000e+00+0.j          4.9999997e-01-0.49999997j\n",
      "   -2.1855694e-08-0.5j        -2.4999999e-01-0.24999999j]\n",
      "  [ 4.9999997e-01+0.49999997j  1.0000000e+00+0.j\n",
      "    4.9999997e-01-0.49999997j -2.1855694e-08-0.5j       ]\n",
      "  [-2.1855694e-08+0.5j         4.9999997e-01+0.49999997j\n",
      "    1.0000000e+00+0.j          4.9999997e-01-0.49999997j]\n",
      "  [-2.4999999e-01+0.24999999j -2.1855694e-08+0.5j\n",
      "    4.9999997e-01+0.49999997j  1.0000000e+00+0.j        ]]\n",
      "\n",
      " [[ 1.0000000e+00+0.j          1.0000001e-01-0.6j\n",
      "   -3.4999999e-01-0.12j       -1.0700002e-01+0.19799998j]\n",
      "  [ 1.0000001e-01+0.6j         1.0000000e+00+0.j\n",
      "    1.0000001e-01-0.6j        -3.4999999e-01-0.12j      ]\n",
      "  [-3.4999999e-01+0.12j        1.0000001e-01+0.6j\n",
      "    1.0000000e+00+0.j          1.0000001e-01-0.6j       ]\n",
      "  [-1.0700002e-01-0.19799998j -3.4999999e-01+0.12j\n",
      "    1.0000001e-01+0.6j         1.0000000e+00+0.j        ]]], shape=(2, 4, 4), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "from sionna import PI\n",
    "from sionna.utils import expand_to_rank\n",
    "\n",
    "def exp_corr_mat(a, n, dtype=tf.complex64):\n",
    "    # Cast to desired output dtype and expand last dimension for broadcasting\n",
    "    a = tf.cast(a, dtype=dtype)\n",
    "    a = tf.expand_dims(a, -1)\n",
    "\n",
    "    # Check that a is valid\n",
    "    msg = \"The absolute value of the elements of `a` must be smaller than one\"\n",
    "    tf.debugging.assert_less(tf.abs(a), tf.cast(1, a.dtype.real_dtype), msg)\n",
    "\n",
    "    # Vector of exponents, adapt dtype and dimensions for broadcasting\n",
    "    exp = tf.range(0, n)\n",
    "    exp = tf.cast(exp, dtype=dtype)\n",
    "    exp = expand_to_rank(exp, tf.rank(a), 0)\n",
    "\n",
    "    # First column of R\n",
    "    col = tf.math.pow(a, exp)\n",
    "\n",
    "    # For a=0, one needs to remove the resulting nans due to 0**0=nan\n",
    "    cond = tf.math.is_nan(tf.math.real(col))\n",
    "    col = tf.where(cond, tf.ones_like(col), col)\n",
    "\n",
    "    # First row of R (equal to complex-conjugate of the first column)\n",
    "    row = tf.math.conj(col)\n",
    "\n",
    "    # Create Toeplitz operator\n",
    "    operator = tf.linalg.LinearOperatorToeplitz(col, row)\n",
    "\n",
    "    # Generate dense tensor from operator\n",
    "    r = operator.to_dense()\n",
    "\n",
    "    return r\n",
    "# 测试例子\n",
    "a = tf.constant([0.5 + 0.5j,0.1+0.6j], dtype=tf.complex64)\n",
    "n = 4\n",
    "result = exp_corr_mat(a, n)\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "tensor([[[ 1.0000e+00+0.0000j,  5.0000e-01-0.5000j, -2.1856e-08-0.5000j,\n",
      "          -2.5000e-01-0.2500j],\n",
      "         [ 5.0000e-01+0.5000j,  1.0000e+00+0.0000j,  5.0000e-01-0.5000j,\n",
      "          -2.1856e-08-0.5000j],\n",
      "         [-2.1856e-08+0.5000j,  5.0000e-01+0.5000j,  1.0000e+00+0.0000j,\n",
      "           5.0000e-01-0.5000j],\n",
      "         [-2.5000e-01+0.2500j, -2.1856e-08+0.5000j,  5.0000e-01+0.5000j,\n",
      "           1.0000e+00+0.0000j]],\n",
      "\n",
      "        [[ 1.0000e+00+0.0000j,  1.0000e-01-0.6000j, -3.5000e-01-0.1200j,\n",
      "          -1.0700e-01+0.1980j],\n",
      "         [ 1.0000e-01+0.6000j,  1.0000e+00+0.0000j,  1.0000e-01-0.6000j,\n",
      "          -3.5000e-01-0.1200j],\n",
      "         [-3.5000e-01+0.1200j,  1.0000e-01+0.6000j,  1.0000e+00+0.0000j,\n",
      "           1.0000e-01-0.6000j],\n",
      "         [-1.0700e-01-0.1980j, -3.5000e-01+0.1200j,  1.0000e-01+0.6000j,\n",
      "           1.0000e+00+0.0000j]]])\n",
      "torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from my_code.mysionna.utils import expand_to_rank\n",
    "from my_code.mysionna import PI\n",
    "\n",
    "def exp_corr_mat(a, n, dtype=torch.complex64):\n",
    "    r\"\"\"Generate exponential correlation matrices.\n",
    "\n",
    "    This function computes for every element :math:`a` of a complex-valued\n",
    "    tensor :math:`\\mathbf{a}` the corresponding :math:`n\\times n` exponential\n",
    "    correlation matrix :math:`\\mathbf{R}(a,n)`, defined as (Eq. 1, [MAL2018]_):\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{R}(a,n)_{i,j} = \\begin{cases}\n",
    "                    1 & \\text{if } i=j\\\\\n",
    "                    a^{i-j}  & \\text{if } i>j\\\\\n",
    "                    (a^\\star)^{j-i}  & \\text{if } j<i, j=1,\\dots,n\\\\\n",
    "                  \\end{cases}\n",
    "\n",
    "    where :math:`|a|<1` and :math:`\\mathbf{R}\\in\\mathbb{C}^{n\\times n}`.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    a : [n_0, ..., n_k], torch.complex\n",
    "        A tensor of arbitrary rank whose elements\n",
    "        have an absolute value smaller than one.\n",
    "\n",
    "    n : int\n",
    "        Number of dimensions of the output correlation matrices.\n",
    "\n",
    "    dtype : torch.complex64, torch.complex128\n",
    "        The dtype of the output.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    R : [n_0, ..., n_k, n, n], torch.complex\n",
    "        A tensor of the same dtype as the input tensor :math:`\\mathbf{a}`.\n",
    "    \"\"\"\n",
    "    if dtype == torch.complex32:\n",
    "        real_dtype = torch.float16\n",
    "    elif dtype == torch.complex64:\n",
    "        real_dtype = torch.float32\n",
    "    elif dtype == torch.complex128:\n",
    "        real_dtype = torch.float64\n",
    "    else:\n",
    "        raise TypeError(\"Not found comfortable type\")\n",
    "\n",
    "    # Cast to desired output dtype and expand last dimension for broadcasting\n",
    "    a = a.to(dtype=dtype)\n",
    "    a = a.unsqueeze(-1)\n",
    "\n",
    "    # Check that a is valid\n",
    "    if not torch.all(torch.abs(a) < 1):\n",
    "        raise ValueError(\"The absolute value of the elements of `a` must be smaller than one\")\n",
    "\n",
    "    # Vector of exponents, adapt dtype and dimensions for broadcasting\n",
    "    exp = torch.arange(0, n, dtype=real_dtype)\n",
    "    exp = exp.to(dtype=dtype) \n",
    "    exp = expand_to_rank(exp, a.dim(),0)\n",
    "\n",
    "    # First column of R\n",
    "    col = torch.pow(a, exp)\n",
    "\n",
    "    # For a=0, one needs to remove the resulting nans due to 0**0=nan\n",
    "    col = torch.where(torch.isnan(col.real), torch.ones_like(col), col)\n",
    "\n",
    "    # First row of R (equal to complex-conjugate of the first column)\n",
    "    row = torch.conj(col)\n",
    "\n",
    "    # Create Toeplitz matrix manually\n",
    "    R = torch.zeros(*a.shape[:-1], n, n,dtype=dtype)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                R[..., i, j] = 1\n",
    "            elif i > j:\n",
    "                R[..., i, j] = col[..., i-j]\n",
    "            else:\n",
    "                R[..., i, j] = row[..., j-i]\n",
    "\n",
    "    return R\n",
    "# 测试例子\n",
    "a = torch.tensor([0.5 + 0.5j,0.1+0.6j], dtype=torch.complex128)\n",
    "n = 4\n",
    "result = exp_corr_mat(a, n)\n",
    "\n",
    "print(\"Result:\")\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
