{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[0.4503, 0.4728, 0.7179],\n",
      "        [0.4728, 0.8853, 1.0855],\n",
      "        [0.7179, 1.0855, 1.5643]])\n",
      "Square root of the tensor:\n",
      " tensor([[0.5082, 0.2051, 0.3873],\n",
      "        [0.2051, 0.7193, 0.5708],\n",
      "        [0.3873, 0.5708, 1.0433]])\n",
      "Product of sqrt and its transpose:\n",
      " tensor([[0.4503, 0.4728, 0.7179],\n",
      "        [0.4728, 0.8853, 1.0855],\n",
      "        [0.7179, 1.0855, 1.5643]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import my_code.mysionna as sn\n",
    "import tensorflow as tf\n",
    "from my_code.mysionna.utils import GLOBAL_SEED_NUMBER\n",
    "import numpy as np\n",
    "\n",
    "def matrix_sqrt(tensor):\n",
    "    r\"\"\" Computes the square root of a matrix.\n",
    "\n",
    "    Given a batch of Hermitian positive semi-definite matrices\n",
    "    :math:`\\mathbf{A}`, returns matrices :math:`\\mathbf{B}`,\n",
    "    such that :math:`\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}`.\n",
    "\n",
    "    The two inner dimensions are assumed to correspond to the matrix rows\n",
    "    and columns, respectively.\n",
    "\n",
    "    Args:\n",
    "        tensor ([..., M, M]) : A tensor of rank greater than or equal\n",
    "            to two.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of the same shape and type as ``tensor`` containing\n",
    "        the matrix square root of its last two dimensions.\n",
    "    \"\"\"\n",
    "    if sn.config.xla_compat and not tensor.is_grad_enabled():\n",
    "        s, u = torch.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = torch.abs(s)\n",
    "        s = torch.sqrt(s)\n",
    "        s = s.type(dtype=u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = s.unsqueeze(-2)\n",
    "        return torch.matmul(u * s, torch.conj(torch.transpose(u, -2, -1)))\n",
    "    else:\n",
    "        s, u = torch.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = torch.abs(s)\n",
    "        s = torch.sqrt(s)\n",
    "        s = s.type(dtype=u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = s.unsqueeze(-2)\n",
    "        return torch.matmul(u * s, torch.conj(torch.transpose(u, -2, -1)))\n",
    "# Example usage:\n",
    "tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "tensor_tf = tf.random.uniform(shape=[3,3])\n",
    "tensor_np = tensor_tf.numpy()\n",
    "tensor = torch.from_numpy(tensor_np)\n",
    "# tensor = torch.randn(3, 3, dtype=torch.float64)\n",
    "tensor = tensor @ tensor.T  # Make it positive semi-definite\n",
    "\n",
    "sqrt_tensor = matrix_sqrt(tensor)\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "print(\"Square root of the tensor:\\n\", sqrt_tensor)\n",
    "print(\"Product of sqrt and its transpose:\\n\", sqrt_tensor @ sqrt_tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix A:\n",
      " tensor([[4.+0.j, 1.+1.j],\n",
      "        [1.-1.j, 3.+0.j]])\n",
      "Matrix Square Root B:\n",
      " tensor([[1.9621+0.0000j, 0.2740+0.2740j],\n",
      "        [0.2740-0.2740j, 1.6882+0.0000j]])\n",
      "Reconstructed Matrix A:\n",
      " tensor([[4.0000+8.2587e-10j, 1.0000+1.0000e+00j],\n",
      "        [1.0000-1.0000e+00j, 3.0000+6.0175e-10j]])\n"
     ]
    }
   ],
   "source": [
    "# 测试例子\n",
    "def test_matrix_sqrt_torch():\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    B = matrix_sqrt(A)\n",
    "\n",
    "    # 验证 B * B^H 是否等于 A\n",
    "    reconstructed_A = torch.matmul(B, B.transpose(-2, -1).conj())\n",
    "    print(\"Original Matrix A:\\n\", A)\n",
    "    print(\"Matrix Square Root B:\\n\", B)\n",
    "    print(\"Reconstructed Matrix A:\\n\", reconstructed_A)\n",
    "\n",
    "test_matrix_sqrt_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix A:\n",
      " [[4.+0.j 1.+1.j]\n",
      " [1.-1.j 3.+0.j]]\n",
      "Matrix Square Root B:\n",
      " [[1.9621162 -2.4636604e-09j 0.27395147+2.7395147e-01j]\n",
      " [0.27395147-2.7395147e-01j 1.688165  +0.0000000e+00j]]\n",
      "Reconstructed Matrix A:\n",
      " [[3.999999  -6.0174798e-10j 0.99999994+9.9999994e-01j]\n",
      " [0.99999994-9.9999994e-01j 2.9999998 -6.0174798e-10j]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sionna as sn\n",
    "def matrix_sqrt(tensor):\n",
    "    r\"\"\" Computes the square root of a matrix.\n",
    "\n",
    "    Given a batch of Hermitian positive semi-definite matrices\n",
    "    :math:`\\mathbf{A}`, returns matrices :math:`\\mathbf{B}`,\n",
    "    such that :math:`\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}`.\n",
    "\n",
    "    The two inner dimensions are assumed to correspond to the matrix rows\n",
    "    and columns, respectively.\n",
    "\n",
    "    Args:\n",
    "        tensor ([..., M, M]) : A tensor of rank greater than or equal\n",
    "            to two.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of the same shape and type as ``tensor`` containing\n",
    "        the matrix square root of its last two dimensions.\n",
    "\n",
    "    Note:\n",
    "        If you want to use this function in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.config.xla_compat`.\n",
    "    \"\"\"\n",
    "    if sn.config.xla_compat and not tf.executing_eagerly():\n",
    "        s, u = tf.linalg.eigh(tensor)\n",
    "\n",
    "        # Compute sqrt of eigenvalues\n",
    "        s = tf.abs(s)\n",
    "        s = tf.sqrt(s)\n",
    "        s = tf.cast(s, u.dtype)\n",
    "\n",
    "        # Matrix multiplication\n",
    "        s = tf.expand_dims(s, -2)\n",
    "        return tf.matmul(u*s, u, adjoint_b=True)\n",
    "    else:\n",
    "        return tf.linalg.sqrtm(tensor)\n",
    "\n",
    "# 测试例子\n",
    "def test_matrix_sqrt_tf():\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = tf.constant([[4 + 0j, 1 + 1j], [1 - 1j, 3 + 0j]], dtype=tf.complex64)\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    B = matrix_sqrt(A)\n",
    "\n",
    "    # 验证 B * B^H 是否等于 A\n",
    "    reconstructed_A = tf.matmul(B, tf.linalg.adjoint(B))\n",
    "    \n",
    "    # 打印结果\n",
    "    print(\"Original Matrix A:\\n\", A.numpy())\n",
    "    print(\"Matrix Square Root B:\\n\", B.numpy())\n",
    "    print(\"Reconstructed Matrix A:\\n\", reconstructed_A.numpy())\n",
    "\n",
    "test_matrix_sqrt_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " [[0.450283915 0.472771168 0.717919]\n",
      " [0.472771168 0.885265 1.08552921]\n",
      " [0.717919 1.08552921 1.56428695]]\n",
      "Square root of the tensor:\n",
      " [[0.508175135 0.205055624 0.387291431]\n",
      " [0.205055609 0.719296813 0.570814967]\n",
      " [0.387291431 0.570815086 1.04329455]]\n",
      "Product of sqrt and its transpose:\n",
      " [[0.450284421 0.472771764 0.717919767]\n",
      " [0.472771764 0.88526547 1.0855298]\n",
      " [0.717919767 1.0855298 1.56428814]]\n"
     ]
    }
   ],
   "source": [
    "# 测试例子\n",
    "def test_matrix_sqrt_tf():\n",
    "    # 创建随机矩阵并使其为正半定矩阵\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "    tensor = tf.random.uniform(shape=[3,3])\n",
    "    tensor = tf.matmul(tensor, tensor, transpose_b=True)  # 使其为正半定矩阵\n",
    "\n",
    "    # 计算矩阵的平方根\n",
    "    sqrt_tensor = matrix_sqrt(tensor)\n",
    "\n",
    "    # 验证 sqrt_tensor * sqrt_tensor^T 是否等于原始矩阵\n",
    "    reconstructed_tensor = tf.matmul(sqrt_tensor, sqrt_tensor, transpose_b=True)\n",
    "    \n",
    "    # 打印结果\n",
    "    tf.print(\"Original tensor:\\n\", tensor)\n",
    "    tf.print(\"Square root of the tensor:\\n\", sqrt_tensor)\n",
    "    tf.print(\"Product of sqrt and its transpose:\\n\", reconstructed_tensor)\n",
    "\n",
    "test_matrix_sqrt_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "h= torch.rand(size=(3,4,6,8,9))\n",
    "print(h.dim())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "h = tf.random.uniform(shape=[3,4,6,8,9])\n",
    "print(tf.rank(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncorrelated channel coefficients:\n",
      " tensor([[ 0.1605+0.6497j, -1.6598+0.3279j],\n",
      "        [-1.2321-0.7520j,  0.5972-0.2143j]])\n",
      "Correlated channel coefficients:\n",
      " tensor([[-0.0706+2.5730j, -4.1521+1.0968j],\n",
      "        [-3.2707-2.4010j,  1.2397-1.2803j]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Various classes for spatially correlated flat-fading channels.\"\"\"\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from my_code.mysionna.utils import expand_to_rank,matrix_sqrt\n",
    "\n",
    "class SpatialCorrelation(ABC):\n",
    "   # pylint: disable=line-too-long\n",
    "    r\"\"\"Abstract class that defines an interface for spatial correlation functions.\n",
    "\n",
    "    The :class:`~sionna.channel.FlatFadingChannel` model can be configured with a\n",
    "    spatial correlation model.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : tf.complex\n",
    "        Tensor of arbitrary shape containing spatially uncorrelated\n",
    "        channel coefficients\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : tf.complex\n",
    "        Tensor of the same shape and dtype as ``h`` containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        return NotImplemented\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    \"\"\"Kronecker model for spatial correlation in PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_tx : [..., K, K], torch.complex\n",
    "        Tensor containing the transmit correlation matrices.\n",
    "\n",
    "    r_rx : [..., M, M], torch.complex\n",
    "        Tensor containing the receive correlation matrices.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], torch.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coefficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], torch.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        r\"\"\"Tensor containing the transmit correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_tx\n",
    "    \n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        r\"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_rx\n",
    "    \n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    "    \n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt,h.dim(),0)\n",
    "            h = torch.matmul(h, r_tx_sqrt.conj().transpose(-2, -1))\n",
    "\n",
    "        \n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, h.dim(),0)\n",
    "            h = torch.matmul(r_rx_sqrt, h)\n",
    "        \n",
    "        return h\n",
    "# 测试例子\n",
    "def test_kronecker_model():\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "\n",
    "    # A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "    # B = torch.tensor([[2, 0], [0, 2]], dtype=torch.complex64)\n",
    "    \n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A = torch.tensor([[4, 1+1j], [1-1j, 3]], dtype=torch.complex64)\n",
    "    B = torch.tensor([[2, 0], [0, 2]], dtype=torch.complex64)    \n",
    "\n",
    "    # 创建 KroneckerModel 实例\n",
    "    model = KroneckerModel(r_tx=A, r_rx=B)\n",
    "\n",
    "    # 创建未相关的通道系数矩阵\n",
    "    h_tf_real = tf.random.normal(shape=[2,2],dtype=tf.float32)\n",
    "    h_tf_img = tf.random.normal(shape=[2,2],dtype=tf.float32)\n",
    "    h_np_real = h_tf_real.numpy()\n",
    "    h_np_img = h_tf_img.numpy()\n",
    "\n",
    "    h_torch_real = torch.tensor(h_np_real, dtype=torch.float32)\n",
    "    h_torch_img = torch.tensor(h_np_img, dtype=torch.float32)\n",
    "    h = torch.complex(h_torch_real,h_torch_img)\n",
    "    \n",
    "    # h = torch.randn(2, 2, dtype=torch.complex64)\n",
    "\n",
    "    # 生成相关的通道系数矩阵\n",
    "    h_corr = model(h)\n",
    "\n",
    "    print(\"Uncorrelated channel coefficients:\\n\", h)\n",
    "    print(\"Correlated channel coefficients:\\n\", h_corr)\n",
    "\n",
    "test_kronecker_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncorrelated channel coefficients:\n",
      " tf.Tensor(\n",
      "[[ 0.16052227+0.64973587j -1.6597689 +0.32791495j]\n",
      " [-1.2321332 -0.75198144j  0.5971658 -0.21430095j]], shape=(2, 2), dtype=complex64)\n",
      "Correlated channel coefficients:\n",
      " tf.Tensor(\n",
      "[[-0.07056929+2.5730007j -4.152109  +1.0967876j]\n",
      " [-3.2706544 -2.40102j    1.2396659 -1.2803249j]], shape=(2, 2), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import tensorflow as tf\n",
    "from tensorflow.experimental.numpy import swapaxes\n",
    "from sionna.utils import expand_to_rank, matrix_sqrt\n",
    "\n",
    "class SpatialCorrelation(ABC):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"Abstract class that defines an interface for spatial correlation functions.\n",
    "\n",
    "    The :class:`~sionna.channel.FlatFadingChannel` model can be configured with a\n",
    "    spatial correlation model.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : tf.complex\n",
    "        Tensor of arbitrary shape containing spatially uncorrelated\n",
    "        channel coefficients\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : tf.complex\n",
    "        Tensor of the same shape and dtype as ``h`` containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def __call__(self, h, *args, **kwargs):\n",
    "        return NotImplemented\n",
    "\n",
    "class KroneckerModel(SpatialCorrelation):\n",
    "    # pylint: disable=line-too-long\n",
    "    r\"\"\"Kronecker model for spatial correlation.\n",
    "\n",
    "    Given a batch of matrices :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`,\n",
    "    :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}`, and\n",
    "    :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`, this function\n",
    "    will generate the following output:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\mathbf{H}_\\text{corr} = \\mathbf{R}^{\\frac12}_\\text{rx} \\mathbf{H} \\mathbf{R}^{\\frac12}_\\text{tx}\n",
    "\n",
    "    Note that :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}` and :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`\n",
    "    must be positive semi-definite, such as the ones generated by\n",
    "    :meth:`~sionna.channel.exp_corr_mat`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    r_tx : [..., K, K], tf.complex\n",
    "        Tensor containing the transmit correlation matrices. If\n",
    "        the rank of ``r_tx`` is smaller than that of the input ``h``,\n",
    "        it will be broadcast.\n",
    "\n",
    "    r_rx : [..., M, M], tf.complex\n",
    "        Tensor containing the receive correlation matrices. If\n",
    "        the rank of ``r_rx`` is smaller than that of the input ``h``,\n",
    "        it will be broadcast.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    h : [..., M, K], tf.complex\n",
    "        Tensor containing spatially uncorrelated\n",
    "        channel coeffficients.\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    h_corr : [..., M, K], tf.complex\n",
    "        Tensor containing the spatially\n",
    "        correlated channel coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, r_tx=None, r_rx=None):\n",
    "        super().__init__()\n",
    "        self.r_tx = r_tx\n",
    "        self.r_rx = r_rx\n",
    "\n",
    "    @property\n",
    "    def r_tx(self):\n",
    "        r\"\"\"Tensor containing the transmit correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_tx\n",
    "\n",
    "    @r_tx.setter\n",
    "    def r_tx(self, value):\n",
    "        self._r_tx = value\n",
    "        if self._r_tx is not None:\n",
    "            self._r_tx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_tx_sqrt = None\n",
    "\n",
    "    @property\n",
    "    def r_rx(self):\n",
    "        r\"\"\"Tensor containing the receive correlation matrices.\n",
    "\n",
    "        Note\n",
    "        ----\n",
    "        If you want to set this property in Graph mode with XLA, i.e., within\n",
    "        a function that is decorated with ``@tf.function(jit_compile=True)``,\n",
    "        you must set ``sionna.Config.xla_compat=true``.\n",
    "        See :py:attr:`~sionna.Config.xla_compat`.\n",
    "        \"\"\"\n",
    "        return self._r_rx\n",
    "\n",
    "    @r_rx.setter\n",
    "    def r_rx(self, value):\n",
    "        self._r_rx = value\n",
    "        if self._r_rx is not None:\n",
    "            self._r_rx_sqrt = matrix_sqrt(value)\n",
    "        else:\n",
    "            self._r_rx_sqrt = None\n",
    "\n",
    "    def __call__(self, h):\n",
    "        if self._r_tx_sqrt is not None:\n",
    "            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n",
    "\n",
    "        if self._r_rx_sqrt is not None:\n",
    "            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n",
    "            h = tf.matmul(r_rx_sqrt, h)\n",
    "\n",
    "        return h\n",
    "    \n",
    "def test_kronecker_model():\n",
    "    # 设置随机种子\n",
    "    tf.random.set_seed(GLOBAL_SEED_NUMBER)\n",
    "\n",
    "    # 创建 Hermitian 正半定矩阵\n",
    "    A_real = tf.constant([[4, 1], [1, 3]], dtype=tf.float32)\n",
    "    A_imag = tf.constant([[0, 1], [-1, 0]], dtype=tf.float32)\n",
    "    A = tf.complex(A_real, A_imag)\n",
    "\n",
    "    B_real = tf.constant([[2, 0], [0, 2]], dtype=tf.float32)\n",
    "    B_imag = tf.constant([[0, 0], [0, 0]], dtype=tf.float32)\n",
    "    B = tf.complex(B_real, B_imag)\n",
    "\n",
    "    # 创建 KroneckerModel 实例\n",
    "    model = KroneckerModel(r_tx=A, r_rx=B)\n",
    "\n",
    "    # 创建未相关的通道系数矩阵\n",
    "    h_real = tf.random.normal(shape=[2, 2], dtype=tf.float32)\n",
    "    h_imag = tf.random.normal(shape=[2, 2], dtype=tf.float32)\n",
    "    h = tf.complex(h_real, h_imag)\n",
    "\n",
    "    # 生成相关的通道系数矩阵\n",
    "    h_corr = model(h)\n",
    "\n",
    "    print(\"Uncorrelated channel coefficients:\\n\", h)\n",
    "    print(\"Correlated channel coefficients:\\n\", h_corr)\n",
    "\n",
    "test_kronecker_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysionna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
